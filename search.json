[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "RTUG",
    "section": "",
    "text": "Affiliation\nThe group has been founded by faculty members of the University of Trento and the group Internet domain name rtug.unitn.it is provided by the same University.\n\n\nSponsor\n\nR-Trento Users Group is kindly sponsored by the R consortium.\nWe follow the R Consortium and the R Community Code of Conduct.\n\n\nLogo\nThe R-Trento Users Group logo uses the green and blue hues from our Province, it has the customary hexagonal shape made popular by tidyverse, and uses the official R language logo in the word “TRENTO”.\nNote that the official R logo is used under Creative Commons Attribution-ShareAlike 4.0 International license (CC-BY-SA 4.0)\n\n\nLicense\nThe content provided by this site are covered by Creative Commons Attribution-ShareAlike 4.0 International license\nThe CC-BY-SA 4.0 license allows you to share and adapt the logo for any purpose, including commercial use, provided that you give appropriate credit, provide a link to the license, and indicate if any changes were made.\n\n\nWebsite\nThis site is built on tools from the R network, using Quarto in the RStudio IDE."
  },
  {
    "objectID": "meetings.html",
    "href": "meetings.html",
    "title": "Meetings",
    "section": "",
    "text": "Meetings organized by RTUG\n\n\n\nMeetings and events are organized and shared via Meetup.com.\nParticipation is free and open to everyone, provided that you sign up for the meeting on Meetup.com.\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\nDescription\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nFirst RTUG meeting\n\n\nPaolo Bosetti\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "members.html",
    "href": "members.html",
    "title": "Members",
    "section": "",
    "text": "Associate professor of Mechanical and Thermal Measurements at the Department of Industrial Engineering, University of Trento.\n\n\n teaching stuff: paolobosetti.quarto.pub\n personal blog\n GitHub page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaria Michela Dickson is Full Professor of Economic Statistics at the Department of Statistical Sciences of the University of Padova.\n\n\n The Department of Statistical Sciences of the University of Padova\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGiuseppe Espa is Full Professor of Economic Statistics at the Department of Economics and Management of the University of Trento. He coordinates the research group StaTA.\n\n\n The StaTA group at University of Trento\n The CSSC research group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFull professor of Economic Statistics at the Department of Economics and Management, University of Trento.\n\n\n The StaTA group at University of Trento\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlavio Santi is Associate Professor of Economic Statistics at the Department of Economics and Management of the University of Trento.\n\n\n Personal website\n The StaTA group at University of Trento\n GitHub code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichele Segata is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento.\n\n\n The MANTA research group web page\n Personal web page\n GitHub code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRocco Micciolo is Full Professor of Medical Statistics at the Department of Psychology and Cognitive Sciences and the Interdepartmental Centre for Medical Sciences-CISMed of the University of Trento\n\n\n DPCS\n Personal web page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYari Ciani is Assistant Professor (RTDa) at the Department of Cellular, Computational and Integrative Biology - CIBIO of the University of Trento.\n\n\n GitHub page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhilippe Velha is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento. He is also affiliated with TIFPA - Trento Institute for Fundamental Physics and Applications.\n\n\n DISI\n TIFPA"
  },
  {
    "objectID": "members.html#paolo-bosetti",
    "href": "members.html#paolo-bosetti",
    "title": "Members",
    "section": "",
    "text": "Associate professor of Mechanical and Thermal Measurements at the Department of Industrial Engineering, University of Trento.\n\n\n teaching stuff: paolobosetti.quarto.pub\n personal blog\n GitHub page"
  },
  {
    "objectID": "members.html#maria-michela-dickson",
    "href": "members.html#maria-michela-dickson",
    "title": "Members",
    "section": "",
    "text": "Maria Michela Dickson is Full Professor of Economic Statistics at the Department of Statistical Sciences of the University of Padova.\n\n\n The Department of Statistical Sciences of the University of Padova"
  },
  {
    "objectID": "members.html#giuseppe-espa",
    "href": "members.html#giuseppe-espa",
    "title": "Members",
    "section": "",
    "text": "Giuseppe Espa is Full Professor of Economic Statistics at the Department of Economics and Management of the University of Trento. He coordinates the research group StaTA.\n\n\n The StaTA group at University of Trento\n The CSSC research group"
  },
  {
    "objectID": "members.html#diego-giuliani",
    "href": "members.html#diego-giuliani",
    "title": "Members",
    "section": "",
    "text": "Full professor of Economic Statistics at the Department of Economics and Management, University of Trento.\n\n\n The StaTA group at University of Trento"
  },
  {
    "objectID": "members.html#flavio-santi",
    "href": "members.html#flavio-santi",
    "title": "Members",
    "section": "",
    "text": "Flavio Santi is Associate Professor of Economic Statistics at the Department of Economics and Management of the University of Trento.\n\n\n Personal website\n The StaTA group at University of Trento\n GitHub code"
  },
  {
    "objectID": "members.html#michele-segata",
    "href": "members.html#michele-segata",
    "title": "Members",
    "section": "",
    "text": "Michele Segata is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento.\n\n\n The MANTA research group web page\n Personal web page\n GitHub code"
  },
  {
    "objectID": "members.html#rocco-micciolo",
    "href": "members.html#rocco-micciolo",
    "title": "Members",
    "section": "",
    "text": "Rocco Micciolo is Full Professor of Medical Statistics at the Department of Psychology and Cognitive Sciences and the Interdepartmental Centre for Medical Sciences-CISMed of the University of Trento\n\n\n DPCS\n Personal web page"
  },
  {
    "objectID": "members.html#yari-ciani",
    "href": "members.html#yari-ciani",
    "title": "Members",
    "section": "",
    "text": "Yari Ciani is Assistant Professor (RTDa) at the Department of Cellular, Computational and Integrative Biology - CIBIO of the University of Trento.\n\n\n GitHub page"
  },
  {
    "objectID": "members.html#philippe-velha",
    "href": "members.html#philippe-velha",
    "title": "Members",
    "section": "",
    "text": "Philippe Velha is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento. He is also affiliated with TIFPA - Trento Institute for Fundamental Physics and Applications.\n\n\n DISI\n TIFPA"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Members posts",
    "section": "",
    "text": "This is a selection of the most interesting posts contributed by our members.\n\n\n\n\n\n\nHow to contribute\n\n\n\nIf you want to contribute, head on to the GitHub repo, fork it, add a new post in the posts folder, tag it with the post category and make a pull request.\n\n\n\n Posts\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTukey vs. Student\n\n5 min\n\n\nR\n\ntidyverse\n\ninference\n\nTukey\n\n\n\nTo compare two samples, or groups, we can use a T-test. But if we want to compare more than two groups, we need to use Tukey’s test. In this post we investigate the reason…\n\n\n\nPaolo Bosetti\n\n\nApr 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTukey’s test plot in adas.utils\n\n3 min\n\n\nR\n\npackages\n\n\n\nThe new version 1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test.\n\n\n\nPaolo Bosetti\n\n\nMar 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the adas.utils package\n\n7 min\n\n\npackages\n\npost\n\nCRAN\n\ndesign of experiments\n\n\n\nThe package adas.utils, contributed by one of RTUG members, aims at helping in the design and analysis of factorial experiments.\n\n\n\nPaolo Bosetti\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogarithmic scales in GGPlot2\n\n5 min\n\n\npost\n\nR\n\ntidyverse\n\nGGPlot2\n\nsignal analysis\n\n\n\nWith the excuse of doing signal analysis in R, this post discusses on how to deal with logarithmic scales and tick-marks in GGPlot2, and how to generate log-spaced grids to…\n\n\n\nPaolo Bosetti\n\n\nFeb 9, 2025\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nNote\n\n\n\n Unless otherwise specified, all content is licensed as BY-NC-SA 4.0."
  },
  {
    "objectID": "posts/003-logscale/index.html",
    "href": "posts/003-logscale/index.html",
    "title": "Logarithmic scales in GGPlot2",
    "section": "",
    "text": "Rationale\nRecently I had to port in R some Matlab code using the tf and bode functions, which are respectively used to calculate the transfer function and create a Bode plot of it.\nThe R package control luckily provides the analogous functions, although its control::bodeplot function uses the base plot interface. Of course, I wanted to make an analogous plot with GGplot2 tools.\n\n\nExample: vibration isolation\nLet us use the example for a lumped parameters model of a vibration isolation system, that is, a 1-DoF mass-spring-damper system. Briefly, its transfer function can be created as:\n\nM &lt;- 10\nK &lt;- 1000\nC &lt;- 50\n\n(H &lt;- tf(c(C/K, 1),c(M/K, C/K, 1)))\n\n\ny1:\n        0.05 s^1 + 1 \n  - - - - - - - - - - - - -\n    0.01 s^2 + 0.05 s + 1 \n\n\nTransfer Function: Continuous time model \n\n\nIts Bode representation can be obtained by:\n\nbode(H) %&gt;% str()\n\nList of 3\n $ w    : num [1:10000] 0 0.01 0.02 0.03 0.04 ...\n $ mag  : num [1:10000] 0.00 8.69e-06 3.48e-05 7.82e-05 1.39e-04 ...\n $ phase: num [1:10000] 0.00 -2.87e-08 -2.29e-07 -7.74e-07 -1.83e-06 ...\n\n\nThat is, a list of three vectors reporting frequency (w), magnitude in dB (mag), and phase in degrees (phase). Why the control developers decided to return a list of equally sized vectors rather a data frame is beyond me, but let’s deal with what we have.\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;% \n  head() %&gt;% \n  knitr::kable()\n\n\n\n\nfrequency (rad/s)\nmagnitude (dB)\nphase (deg)\n\n\n\n\n1\n0.0870762\n-0.0288644\n\n\n2\n0.3509189\n-0.2362699\n\n\n3\n0.7993794\n-0.8294252\n\n\n4\n1.4452744\n-2.0825653\n\n\n5\n2.3044892\n-4.3987054\n\n\n6\n3.3880407\n-8.4155907\n\n\n\n\n\nTo make the Bode plot, which reports magnitude vs. frequency on top of phase vs. frequency, we make the tibble tidy and use facet_wrap:\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10()\n\n\n\n\n\n\n\n\nNote the followings:\n\nin facet_wrap, we use the option scales=\"free\": this allows to independently rescale the axes of each facet;\nthe horizontal axis is logarithmic, but there is only one secondary grid line, while we usually have secondary gridlines at 2, 3, …, 9;\nthe point density is not evenly spaced on the logarithmic axis.\n\nSo, here we want to tackle the problems in 2. and 3..\n\n\nLog-tickmarks: Solution\nThe scale_x_log10() function allows to specify the breaks and the minor_breaks, which we can exploit to fix the gridlines. How can we get a log-spaced sequence? an elegant solution uses the outer product %o% of two vectors: that of the ticks, and that of the orders of magnitude (ooms):\n\nticks &lt;- 2:9\nooms &lt;- 10^seq(0, 4)\n\nticks %o% ooms\n\n     [,1] [,2] [,3] [,4]  [,5]\n[1,]    2   20  200 2000 20000\n[2,]    3   30  300 3000 30000\n[3,]    4   40  400 4000 40000\n[4,]    5   50  500 5000 50000\n[5,]    6   60  600 6000 60000\n[6,]    7   70  700 7000 70000\n[7,]    8   80  800 8000 80000\n[8,]    9   90  900 9000 90000\n\n\nLooking at the columns , in sequence, we have what we want, so:\n\n(breaks &lt;- as.vector(ticks %o% ooms))\n\n [1]     2     3     4     5     6     7     8     9    20    30    40    50\n[13]    60    70    80    90   200   300   400   500   600   700   800   900\n[25]  2000  3000  4000  5000  6000  7000  8000  9000 20000 30000 40000 50000\n[37] 60000 70000 80000 90000\n\n\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10(minor_breaks=breaks, labels=scales::scientific)\n\n\n\n\n\n\n\n\nBingo!\nNow, we still have too sparse points to the left, and definitely too many points to the right. We can use a similar approach to define the frequency vector.\n\n\nLog-spaced points: Solution\nWe use the same outer product trick, multiplying the vector of orders of magnitude by a vector of positions, exponentially spaced within each magnitude:\n\npts &lt;- 10^seq(0, 1, 0.1) %&gt;% tail(-1)\n(freqs &lt;- as.vector(pts %o% ooms)) %&gt;% head(n=20)\n\n [1]   1.258925   1.584893   1.995262   2.511886   3.162278   3.981072\n [7]   5.011872   6.309573   7.943282  10.000000  12.589254  15.848932\n[13]  19.952623  25.118864  31.622777  39.810717  50.118723  63.095734\n[19]  79.432823 100.000000\n\n\nFinally:\n\npts &lt;- 10^seq(0, 1, 0.01) %&gt;% tail(-1)\nfreqs &lt;- as.vector(pts %o% ooms)\n\nbode(H, w=freqs) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10(minor_breaks=breaks, labels=scales::scientific)\n\n\n\n\n\n\n\n\n\n\nPutting all together\nWe can then put everything together and make a useful function (note that we are now converting the frequencies to Hz):\n\nggbodeplot &lt;- function(tf, fmin=1, fmax=1e4, df=0.01) {\n  ticks &lt;- 2:9\n  pts &lt;- 10^seq(0, 1, df) %&gt;% tail(-1)\n  ooms &lt;- 10^(floor(log10(fmin)):ceiling(log10(fmax)-1))\n  breaks &lt;- as.vector(ticks %o% ooms)\n  freqs &lt;- as.vector(pts %o% ooms)\n  \n  bode(tf, freqs*2*pi) %&gt;% {\n    tibble(f=.$w/(2*pi), `magnitude (dB)`=.$mag, `phase (deg)`=.$phase)} %&gt;% \n    pivot_longer(-f) %&gt;% \n    ggplot(aes(x=f, y=value)) +\n    geom_line() +\n    scale_x_log10(minor_breaks=breaks, labels=scales::scientific) +\n    facet_wrap(~name, nrow=2, scales=\"free\") +\n    labs(x=\"frequency (Hz)\")\n}\n\nH %&gt;% ggbodeplot(fmin=0.1, fmax=100)\n\n\n\n\n\n\n\n\n\n\nOne last thing…\nWell, the above is mostly of academic interest, at least for what pertains the logarithmic grid lines: it shows a nice and useful way for creating regularly spaced vectors, which is really useful to evenly distribute abscissa values when the axis scale is not linear. But thanks to the scales package there is a quick way for having any axis, whichever the scale, with a number of minor breaks different to 1 (the defaiult in GGplot). In fact, we can just use the scales::minor_breaks_n() function to generate minor grid lines at will:\n\nggbodeplot &lt;- function(tf, fmin=1, fmax=1e4, df=0.01) {\n  pts &lt;- 10^seq(0, 1, df) %&gt;% tail(-1)\n  ooms &lt;- 10^(floor(log10(fmin)):ceiling(log10(fmax)-1))\n  freqs &lt;- as.vector(pts %o% ooms)\n  \n  bode(tf, freqs*2*pi) %&gt;% {\n    tibble(f=.$w/(2*pi), `magnitude (dB)`=.$mag, `phase (deg)`=.$phase)} %&gt;% \n    pivot_longer(-f) %&gt;% \n    ggplot(aes(x=f, y=value)) +\n    geom_line() +\n    scale_x_log10(\n      minor_breaks=scales::minor_breaks_n(10), \n      labels= ~ latex2exp::TeX(paste0(\"$10^{\", log10(.), \"}$\"))\n    ) +\n    facet_wrap(~name, nrow=2, scales=\"free\") +\n    labs(x=\"frequency (Hz)\")\n}\n\nH %&gt;% ggbodeplot(fmin=0.1, fmax=100)\n\n\n\n\n\n\n\n\nwhere the trick is to set scale_x_log10(minor_breaks=scales::minor_breaks_n(10)). Note that the argument is the number of intervals rather than the number of grid lines (so, 10 rather than 9). As a final suggestion, try and use the same command with a scale_x_continuous: it works whichever is the axis transformation (including identity). Also, note the labels lambda function used for formatting tick labels.\n\nThat’s all, folks!"
  },
  {
    "objectID": "posts/006-tukey/index.html",
    "href": "posts/006-tukey/index.html",
    "title": "Tukey’s test plot in adas.utils",
    "section": "",
    "text": "The new version v1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test. The function is called ggTukey and it is used to plot the results of Tukey’s test provided by the stas::TukeyHSD function.\n\n\n\n\n\nJohn W. Tukey\n\n\nThe standard stats::TukeyHSD function returns an S3 object that has the print and plot methods. The result of the plot method, though, is honestly not really appealing. Let’s see how it works, by loading a dataset and running a Tukey’s test on it. We load an online dataset by using the adas.utils::examples_url function1, and we begin with a simple boxplot of the data.\n\nlibrary(tidyverse)\nlibrary(adas.utils)\n\ndata &lt;- examples_url(\"anova.dat\") %&gt;% \n  read.table(header=TRUE) %&gt;% \n  mutate(Cotton=factor(Cotton)) %&gt;% \n  glimpse()\n\nRows: 25\nColumns: 3\n$ Cotton      &lt;fct&gt; 15, 15, 15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25…\n$ Observation &lt;int&gt; 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5…\n$ Strength    &lt;int&gt; 7, 7, 15, 11, 9, 12, 17, 12, 18, 18, 14, 18, 18, 19, 19, 1…\n\ndata %&gt;% \n  ggplot(aes(x=Cotton, y=Strength, group=Cotton)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe Tukey’s test is built by using the aov function and the TukeyHSD function. The results are then plotted by the plot method of the TukeyHSD object:\n\ndata %&gt;% \n  aov(Strength ~ Cotton, data=.) %&gt;%\n  TukeyHSD() %&gt;% \n  plot()\n\n\n\n\n\n\n\n\nThe biggest problem with plot.TukeyHSD is that the labels of the differences are often partially hidden if there are many groups or the plot is too squat. This is the main reason for implementing an analogous function based on GGplot2 in adas.utils."
  },
  {
    "objectID": "posts/006-tukey/index.html#footnotes",
    "href": "posts/006-tukey/index.html#footnotes",
    "title": "Tukey’s test plot in adas.utils",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis function can load any data file listed on https://paolobosetti.quarto.pub/data↩︎"
  },
  {
    "objectID": "posts/005-domain/index.html",
    "href": "posts/005-domain/index.html",
    "title": "Moving to a new domain",
    "section": "",
    "text": "Starting from February 26, 2025, RTUG website has a new domain under the University of Trento domain: rtug.unitn.it. So the group’s homepage is now accessible as https://rtug.unitn.it.\nFurthermore, there is a new contact email address: mailto:rtug.group@unitn.it (rtug.group at unitn dot it)\n\n\n\n\n\n\nNote\n\n\n\nThe old address https://r-trento.github.io will continue to work, automatically redirecting to the new domain name.\n\n\n\nThat’s all, folks!"
  },
  {
    "objectID": "posts/004-adas.utils/index.html",
    "href": "posts/004-adas.utils/index.html",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "The package provides tools for dealing with factorial plan according to the Design of Experiments (DoE) protocols. The functions for dealing with DoE have names starting with fp_. As much as possible, we are aiming at a tidyverse-like syntax, so that the functions can be used in a pipe.\nWe are following conventions and techniques illustrated in the book Design and Analysis of Experiments by Douglas C. Montgomery.\n\n\n\n\n\n\n\nA hypercube, clearly impossible to represent in 2D\n\n\nYou can create a full factorial plan with the fp_design_matrix function, passing the number of factors:\n\n(dm &lt;- fp_design_matrix(2, rep=2) %&gt;% \n  mutate(Y=rnorm(n())))\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 8 × 7\n#&gt;   StdOrder RunOrder .treat  .rep     A     B       Y\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1        1        5 (1)        1    -1    -1 -0.439 \n#&gt; 2        2        8 a          1     1    -1  0.0520\n#&gt; 3        3        2 b          1    -1     1  0.101 \n#&gt; 4        4        6 ab         1     1     1  0.571 \n#&gt; 5        5        4 (1)        2    -1    -1 -1.23  \n#&gt; 6        6        3 a          2     1    -1 -2.40  \n#&gt; 7        7        7 b          2    -1     1  1.13  \n#&gt; 8        8        1 ab         2     1     1  0.0625\n\nIn this case, the factors are the first n capital letters.\nIf you want different factor names, use a right-side-only formula combining all the named factors with *:\n\nfp_design_matrix(~Speed*Weight)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ Speed * Weight \n#&gt;  Factors:  Speed Weight \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 4 × 7\n#&gt;   StdOrder RunOrder .treat       .rep Speed Weight Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        4 (1)             1    -1     -1 NA   \n#&gt; 2        2        1 speed           1     1     -1 NA   \n#&gt; 3        3        2 weight          1    -1      1 NA   \n#&gt; 4        4        3 speedweight     1     1      1 NA\n\nNOTE, though, that using custom factor names is discouraged, and won’t work as expected if you are using the functions for dealing with fractional factorial plans, especially for the analysis of alias structures among factors.\nThe yield column Y must then be completed according to the randomized RunOrder column.\nIt is possible to add custom scales to the factors, and also add names to the factors:\n\nfp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;%\n  fp_add_scale(A=c(20, 25), B=c(75, 125), suffix=\".scaled\")\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  Scaled factors:\n#&gt;     A: [20, 25]\n#&gt;     B: [75, 125]\n#&gt;  Factor names:\n#&gt;     A: Temperature\n#&gt;     B: Pressure\n#&gt;  \n#&gt; # A tibble: 4 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B A.scaled B.scaled Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        1 (1)        1    -1    -1       20       75 NA   \n#&gt; 2        2        4 a          1     1    -1       25       75 NA   \n#&gt; 3        3        2 b          1    -1     1       20      125 NA   \n#&gt; 4        4        3 ab         1     1     1       25      125 NA\n\n\n\n\nIf you want a \\(k^n\\) factorial plan with custom levels, pass the levels argument. In this case, though, the .treat column with Yates’ treatment codes would be NA:\n\nfp_design_matrix(2, levels=-1:1)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 0 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 9 × 6\n#&gt;   StdOrder RunOrder  .rep     A     B Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;\n#&gt; 1        1        8     1    -1    -1 NA   \n#&gt; 2        2        5     1     0    -1 NA   \n#&gt; 3        3        3     1     1    -1 NA   \n#&gt; 4        4        6     1    -1     0 NA   \n#&gt; 5        5        7     1     0     0 NA   \n#&gt; 6        6        1     1     1     0 NA   \n#&gt; 7        7        9     1    -1     1 NA   \n#&gt; 8        8        2     1     0     1 NA   \n#&gt; 9        9        4     1     1     1 NA\n\n\n\n\nYou can augment a plan by adding a central point, typically repeated:\n\nfp_design_matrix(3) %&gt;%\n  fp_augment_center(rep=4)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  centered \n#&gt;  \n#&gt; # A tibble: 12 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        5 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        8 a          1     1    -1    -1 NA   \n#&gt;  3        3        6 b          1    -1     1    -1 NA   \n#&gt;  4        4        4 ab         1     1     1    -1 NA   \n#&gt;  5        5        2 c          1    -1    -1     1 NA   \n#&gt;  6        6        1 ac         1     1    -1     1 NA   \n#&gt;  7        7        7 bc         1    -1     1     1 NA   \n#&gt;  8        8        3 abc        1     1     1     1 NA   \n#&gt;  9        9       11 center     1     0     0     0 NA   \n#&gt; 10       10       10 center     2     0     0     0 NA   \n#&gt; 11       11       12 center     3     0     0     0 NA   \n#&gt; 12       12        9 center     4     0     0     0 NA\n\nThen if needed (because the analysis show low p-value for the quadratic term) you can add axial points to get a central composite design:\n\nfp_design_matrix(3) %&gt;% \n  fp_augment_center(rep=3) %&gt;% \n  fp_augment_axial(rep=2)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  composite \n#&gt;  \n#&gt; # A tibble: 35 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        7 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        3 a          1     1    -1    -1 NA   \n#&gt;  3        3        2 b          1    -1     1    -1 NA   \n#&gt;  4        4        1 ab         1     1     1    -1 NA   \n#&gt;  5        5        5 c          1    -1    -1     1 NA   \n#&gt;  6        6        6 ac         1     1    -1     1 NA   \n#&gt;  7        7        8 bc         1    -1     1     1 NA   \n#&gt;  8        8        4 abc        1     1     1     1 NA   \n#&gt;  9        9        9 center     1     0     0     0 NA   \n#&gt; 10       10       11 center     2     0     0     0 NA   \n#&gt; # ℹ 25 more rows\n\n\n\nLet’s see a full example using the ccd_experiment_yield dataset, which contains a list of the yield data for three sequential experiments in a central composite design.\nFirst, we design a \\(3\\cdot 2^2\\) factorial plan, with two factors and two levels each:\n\nfp &lt;- fp_design_matrix(2, rep=3)\n\nIdeally, we would then sort the table according to the RunOrder column, and complete the Y column with the yield data from the the real experiments. For the sake of documenting the package, we can directly add the yield data from the base field of the ccd_experiment_yield dataset (which holds values in standard Yates’ order):\n\nfp$Y &lt;- ccd_experiment_yield$base\n\nNow we can fit a linear model to the data, and check the p-values of the ANOVA:\n\nfp %&gt;% \n  lm(Y ~ A*B, data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  105.06 7.058e-06 ***\n#&gt; B          1 131.224 131.224  279.46 1.659e-07 ***\n#&gt; A:B        1 216.931 216.931  461.99 2.311e-08 ***\n#&gt; Residuals  8   3.756   0.470                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAll factors and their interactions are significant. But is the two-level model enough? Let’s check for the quadratic terms, by augmenting the plan with a central point repeated 4 times. We also load the center field from the ccd_experiment_yield dataset:\n\nfpc &lt;- fp %&gt;% \n  fp_augment_center(rep=4)\n\nfpc$Y[fpc$.treat == \"center\"] &lt;- ccd_experiment_yield$center\n\nNow we can fit a model with the quadratic term, using either \\(A\\) or \\(B\\): since we only have a central point, we cannot discriminate which factor is contributing to the curvature in the response surface. We get:\n\nfpc %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  96.801 8.695e-07 ***\n#&gt; B          1 131.224 131.224 257.494 5.592e-09 ***\n#&gt; I(A^2)     1  15.204  15.204  29.834 0.0001972 ***\n#&gt; A:B        1 216.931 216.931 425.673 3.827e-10 ***\n#&gt; Residuals 11   5.606   0.510                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo the contribution of the quadratic term is significant. This means that we have to further augment the plan with axial points and investigate a Central Composite Design (CCD). Note: if the quadratic term contribution were not significant, we would have to remove the quadratic term from the model and accept the two-level model.\nSo let’s load the axial points from the axial field of the ccd_experiment_yield dataset, and fit a model with the quadratic terms and their interactions:\n\nfpccd &lt;- fpc %&gt;% \n  fp_augment_axial(rep=2)\n\nfpccd$Y[fpccd$.treat == \"axial\"] &lt;- ccd_experiment_yield$axial\n\nfpccd %&gt;% \n  lm(Y ~ A*B*I(A^2)*I(B^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;               Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    \n#&gt; A              1  75.196  75.196  94.1952 7.395e-08 ***\n#&gt; B              1 194.702 194.702 243.8964 1.097e-10 ***\n#&gt; I(A^2)         1 101.355 101.355 126.9638 1.017e-08 ***\n#&gt; I(B^2)         1   3.551   3.551   4.4479   0.05216 .  \n#&gt; A:B            1 216.931 216.931 271.7423 5.087e-11 ***\n#&gt; A:I(A^2)       1   0.235   0.235   0.2945   0.59530    \n#&gt; B:I(A^2)       1   1.046   1.046   1.3106   0.27022    \n#&gt; I(A^2):I(B^2)  1   0.490   0.490   0.6142   0.44542    \n#&gt; Residuals     15  11.974   0.798                       \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo we can finally state that a proper model would be Y ~ A*B+I(A^2):\n\nfpccd %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Y ~ A * B + I(A^2), data = .)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.64925 -0.60624  0.00919  0.65165  1.67506 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0156     0.3061   3.318  0.00362 ** \n#&gt; A             1.9390     0.2134   9.088 2.40e-08 ***\n#&gt; B             3.1201     0.2134  14.624 8.59e-12 ***\n#&gt; I(A^2)        2.9905     0.2834  10.552 2.20e-09 ***\n#&gt; A:B           4.2518     0.2754  15.437 3.32e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9541 on 19 degrees of freedom\n#&gt; Multiple R-squared:  0.9714, Adjusted R-squared:  0.9654 \n#&gt; F-statistic: 161.5 on 4 and 19 DF,  p-value: 2.191e-14\n\n\n\n\n\nOnce the design matrix is prepared, you typically want to save it to a file and use it for collecting data form experiments. You can use the write.csv function, but it is recommended to use the fp_write_csv function, which will also save the design matrix properties as comments:\n\ndm &lt;-  fp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;% \n  fp_add_scale(A=c(2, 12), B=c(40, 60), suffix=\"_s\") %&gt;%\n  fp_write_csv(\"design_matrix.csv\")\n\nNote that the fp_write_csv function invisibly returns the same design matrix, so you can use it in a pipe chain. Also, the CVS files has the rows arranged in the same order as the RunOrder column (i.e. randomized).\nOnce the CSV file has been completed, you can load it back into R using the fp_read_csv function:\n\ndm &lt;- dm %&gt;% \n  fp_read_csv(\"design_matrix.csv\")\n\nNote that fp_read_csv returns the design matrix reordered according to Yates’ standard order.\n\n\n\nIt is possible to divide a design matrix into a fractional factorial plan using the fp_fraction function. The fraction uses a defining relationship (dr) as \\(I=ABCD\\), which is mapped in R as a one side formula ~A*B*C*D.\nAny fraction is added to the factorial.plan object in the fraction attribute.\nA full \\(2^n\\) factorial plan can be reduced to a fractional factorial plan \\(2^{n-p}\\) by applying the fp_fraction function \\(p\\) times. For example, to get a \\(2^{5-2}\\) plan with the defining relationships \\(I=ABCD\\) and \\(I=BCDE\\):\n\nfp_design_matrix(5) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_fraction(~B*C*D*E)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C * D * E \n#&gt;  Factors:  A B C D E \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABCD I=BCDE \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 12\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C     D     E Y      ABCD  BCDE\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1        1        8 (1)        1    -1    -1    -1    -1    -1 NA        1     1\n#&gt; 2        7       14 bc         1    -1     1     1    -1    -1 NA        1     1\n#&gt; 3       11        6 bd         1    -1     1    -1     1    -1 NA        1     1\n#&gt; 4       13        4 cd         1    -1    -1     1     1    -1 NA        1     1\n#&gt; 5       20       24 abe        1     1     1    -1    -1     1 NA        1     1\n#&gt; 6       22       29 ace        1     1    -1     1    -1     1 NA        1     1\n#&gt; 7       26        2 ade        1     1    -1    -1     1     1 NA        1     1\n#&gt; 8       32       22 abcde      1     1     1     1     1     1 NA        1     1\n\nNote that with the remove option you can control if you want to keep both fractions, and later on filter(ABC==1) them out.\n\nfp_design_matrix(3) %&gt;% \n  fp_fraction(~A*B*C, remove=FALSE)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABC \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C Y       ABC\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;\n#&gt; 1        1        2 (1)        1    -1    -1    -1 NA       -1\n#&gt; 2        2        5 a          1     1    -1    -1 NA        1\n#&gt; 3        3        4 b          1    -1     1    -1 NA        1\n#&gt; 4        4        8 ab         1     1     1    -1 NA       -1\n#&gt; 5        5        1 c          1    -1    -1     1 NA        1\n#&gt; 6        6        7 ac         1     1    -1     1 NA       -1\n#&gt; 7        7        3 bc         1    -1     1     1 NA       -1\n#&gt; 8        8        6 abc        1     1     1     1 NA        1\n\nAlso, note that the remove option is sticky, so that when you can apply the fp_fraction function multiple times and the first time has the option set to remove=FALSE, then all the following fp_fraction calls will have the same option set to FALSE. Setting remove=FALSE to any of the following calls can have unexpected behavior.\n\n\n\nAny fraction of a factorial plan results in a set of aliases among effects. The package provides the following functions to deal with alias structures:\n\nfp_alias_matrix: returns a matrix with the alias structure of the factors in the design matrix. The alias matrix has a plot method.\nfp_all_drs: given a set of defining relationships, returns the dependent one.\nfp_merge_drs: given a set of defining relationships, returns the merged one, i.e. the one having all the factors.\nfp_gen2alias: given a generator (i.e. the right side of a DR) and an effect name as strings, calculates the resulting alias.\n\nFor example:\n\n(am &lt;- fp_alias_matrix(~A*B*C, ~B*C*D))\n#&gt; Defining relationships:\n#&gt;  I=ABC I=BCD I=AD \n#&gt; \n#&gt;      A B AB C AC BC ABC D AD BD ABD CD ACD BCD ABCD\n#&gt; A    0 0  0 0  0  1   0 3  0  0   0  0   0   0    2\n#&gt; B    0 0  0 0  1  0   0 0  0  0   3  2   0   0    0\n#&gt; AB   0 0  0 1  0  0   0 0  0  3   0  0   2   0    0\n#&gt; C    0 0  1 0  0  0   0 0  0  2   0  0   3   0    0\n#&gt; AC   0 1  0 0  0  0   0 0  0  0   2  3   0   0    0\n#&gt; BC   1 0  0 0  0  0   0 2  0  0   0  0   0   0    3\n#&gt; ABC  0 0  0 0  0  0   0 0  2  0   0  0   0   3    0\n#&gt; D    3 0  0 0  0  2   0 0  0  0   0  0   0   0    1\n#&gt; AD   0 0  0 0  0  0   2 0  0  0   0  0   0   1    0\n#&gt; BD   0 0  3 2  0  0   0 0  0  0   0  0   1   0    0\n#&gt; ABD  0 3  0 0  2  0   0 0  0  0   0  1   0   0    0\n#&gt; CD   0 2  0 0  3  0   0 0  0  0   1  0   0   0    0\n#&gt; ACD  0 0  2 3  0  0   0 0  0  1   0  0   0   0    0\n#&gt; BCD  0 0  0 0  0  0   3 0  1  0   0  0   0   0    0\n#&gt; ABCD 2 0  0 0  0  3   0 1  0  0   0  0   0   0    0\n\n\nam %&gt;% plot()\n\n\n\n\n\n\n\n\nThe design matrix can be converted to a tibble thanks to the proper as_tibble.design.matrix S3 method:\n\nam %&gt;% as_tibble()\n#&gt; # A tibble: 42 × 3\n#&gt;    Effect.x Effect.y generator\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    \n#&gt;  1 A        BC       ABC      \n#&gt;  2 A        D        AD       \n#&gt;  3 A        ABCD     BCD      \n#&gt;  4 B        AC       ABC      \n#&gt;  5 B        ABD      AD       \n#&gt;  6 B        CD       BCD      \n#&gt;  7 AB       C        ABC      \n#&gt;  8 AB       BD       AD       \n#&gt;  9 AB       ACD      BCD      \n#&gt; 10 C        AB       ABC      \n#&gt; # ℹ 32 more rows"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#full-factorial-plan",
    "href": "posts/004-adas.utils/index.html#full-factorial-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "A hypercube, clearly impossible to represent in 2D\n\n\nYou can create a full factorial plan with the fp_design_matrix function, passing the number of factors:\n\n(dm &lt;- fp_design_matrix(2, rep=2) %&gt;% \n  mutate(Y=rnorm(n())))\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 8 × 7\n#&gt;   StdOrder RunOrder .treat  .rep     A     B       Y\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1        1        5 (1)        1    -1    -1 -0.439 \n#&gt; 2        2        8 a          1     1    -1  0.0520\n#&gt; 3        3        2 b          1    -1     1  0.101 \n#&gt; 4        4        6 ab         1     1     1  0.571 \n#&gt; 5        5        4 (1)        2    -1    -1 -1.23  \n#&gt; 6        6        3 a          2     1    -1 -2.40  \n#&gt; 7        7        7 b          2    -1     1  1.13  \n#&gt; 8        8        1 ab         2     1     1  0.0625\n\nIn this case, the factors are the first n capital letters.\nIf you want different factor names, use a right-side-only formula combining all the named factors with *:\n\nfp_design_matrix(~Speed*Weight)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ Speed * Weight \n#&gt;  Factors:  Speed Weight \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 4 × 7\n#&gt;   StdOrder RunOrder .treat       .rep Speed Weight Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        4 (1)             1    -1     -1 NA   \n#&gt; 2        2        1 speed           1     1     -1 NA   \n#&gt; 3        3        2 weight          1    -1      1 NA   \n#&gt; 4        4        3 speedweight     1     1      1 NA\n\nNOTE, though, that using custom factor names is discouraged, and won’t work as expected if you are using the functions for dealing with fractional factorial plans, especially for the analysis of alias structures among factors.\nThe yield column Y must then be completed according to the randomized RunOrder column.\nIt is possible to add custom scales to the factors, and also add names to the factors:\n\nfp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;%\n  fp_add_scale(A=c(20, 25), B=c(75, 125), suffix=\".scaled\")\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  Scaled factors:\n#&gt;     A: [20, 25]\n#&gt;     B: [75, 125]\n#&gt;  Factor names:\n#&gt;     A: Temperature\n#&gt;     B: Pressure\n#&gt;  \n#&gt; # A tibble: 4 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B A.scaled B.scaled Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        1 (1)        1    -1    -1       20       75 NA   \n#&gt; 2        2        4 a          1     1    -1       25       75 NA   \n#&gt; 3        3        2 b          1    -1     1       20      125 NA   \n#&gt; 4        4        3 ab         1     1     1       25      125 NA"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#custom-levels",
    "href": "posts/004-adas.utils/index.html#custom-levels",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "If you want a \\(k^n\\) factorial plan with custom levels, pass the levels argument. In this case, though, the .treat column with Yates’ treatment codes would be NA:\n\nfp_design_matrix(2, levels=-1:1)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 0 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 9 × 6\n#&gt;   StdOrder RunOrder  .rep     A     B Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;\n#&gt; 1        1        8     1    -1    -1 NA   \n#&gt; 2        2        5     1     0    -1 NA   \n#&gt; 3        3        3     1     1    -1 NA   \n#&gt; 4        4        6     1    -1     0 NA   \n#&gt; 5        5        7     1     0     0 NA   \n#&gt; 6        6        1     1     1     0 NA   \n#&gt; 7        7        9     1    -1     1 NA   \n#&gt; 8        8        2     1     0     1 NA   \n#&gt; 9        9        4     1     1     1 NA"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#augment-a-plan",
    "href": "posts/004-adas.utils/index.html#augment-a-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "You can augment a plan by adding a central point, typically repeated:\n\nfp_design_matrix(3) %&gt;%\n  fp_augment_center(rep=4)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  centered \n#&gt;  \n#&gt; # A tibble: 12 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        5 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        8 a          1     1    -1    -1 NA   \n#&gt;  3        3        6 b          1    -1     1    -1 NA   \n#&gt;  4        4        4 ab         1     1     1    -1 NA   \n#&gt;  5        5        2 c          1    -1    -1     1 NA   \n#&gt;  6        6        1 ac         1     1    -1     1 NA   \n#&gt;  7        7        7 bc         1    -1     1     1 NA   \n#&gt;  8        8        3 abc        1     1     1     1 NA   \n#&gt;  9        9       11 center     1     0     0     0 NA   \n#&gt; 10       10       10 center     2     0     0     0 NA   \n#&gt; 11       11       12 center     3     0     0     0 NA   \n#&gt; 12       12        9 center     4     0     0     0 NA\n\nThen if needed (because the analysis show low p-value for the quadratic term) you can add axial points to get a central composite design:\n\nfp_design_matrix(3) %&gt;% \n  fp_augment_center(rep=3) %&gt;% \n  fp_augment_axial(rep=2)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  composite \n#&gt;  \n#&gt; # A tibble: 35 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        7 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        3 a          1     1    -1    -1 NA   \n#&gt;  3        3        2 b          1    -1     1    -1 NA   \n#&gt;  4        4        1 ab         1     1     1    -1 NA   \n#&gt;  5        5        5 c          1    -1    -1     1 NA   \n#&gt;  6        6        6 ac         1     1    -1     1 NA   \n#&gt;  7        7        8 bc         1    -1     1     1 NA   \n#&gt;  8        8        4 abc        1     1     1     1 NA   \n#&gt;  9        9        9 center     1     0     0     0 NA   \n#&gt; 10       10       11 center     2     0     0     0 NA   \n#&gt; # ℹ 25 more rows\n\n\n\nLet’s see a full example using the ccd_experiment_yield dataset, which contains a list of the yield data for three sequential experiments in a central composite design.\nFirst, we design a \\(3\\cdot 2^2\\) factorial plan, with two factors and two levels each:\n\nfp &lt;- fp_design_matrix(2, rep=3)\n\nIdeally, we would then sort the table according to the RunOrder column, and complete the Y column with the yield data from the the real experiments. For the sake of documenting the package, we can directly add the yield data from the base field of the ccd_experiment_yield dataset (which holds values in standard Yates’ order):\n\nfp$Y &lt;- ccd_experiment_yield$base\n\nNow we can fit a linear model to the data, and check the p-values of the ANOVA:\n\nfp %&gt;% \n  lm(Y ~ A*B, data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  105.06 7.058e-06 ***\n#&gt; B          1 131.224 131.224  279.46 1.659e-07 ***\n#&gt; A:B        1 216.931 216.931  461.99 2.311e-08 ***\n#&gt; Residuals  8   3.756   0.470                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAll factors and their interactions are significant. But is the two-level model enough? Let’s check for the quadratic terms, by augmenting the plan with a central point repeated 4 times. We also load the center field from the ccd_experiment_yield dataset:\n\nfpc &lt;- fp %&gt;% \n  fp_augment_center(rep=4)\n\nfpc$Y[fpc$.treat == \"center\"] &lt;- ccd_experiment_yield$center\n\nNow we can fit a model with the quadratic term, using either \\(A\\) or \\(B\\): since we only have a central point, we cannot discriminate which factor is contributing to the curvature in the response surface. We get:\n\nfpc %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  96.801 8.695e-07 ***\n#&gt; B          1 131.224 131.224 257.494 5.592e-09 ***\n#&gt; I(A^2)     1  15.204  15.204  29.834 0.0001972 ***\n#&gt; A:B        1 216.931 216.931 425.673 3.827e-10 ***\n#&gt; Residuals 11   5.606   0.510                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo the contribution of the quadratic term is significant. This means that we have to further augment the plan with axial points and investigate a Central Composite Design (CCD). Note: if the quadratic term contribution were not significant, we would have to remove the quadratic term from the model and accept the two-level model.\nSo let’s load the axial points from the axial field of the ccd_experiment_yield dataset, and fit a model with the quadratic terms and their interactions:\n\nfpccd &lt;- fpc %&gt;% \n  fp_augment_axial(rep=2)\n\nfpccd$Y[fpccd$.treat == \"axial\"] &lt;- ccd_experiment_yield$axial\n\nfpccd %&gt;% \n  lm(Y ~ A*B*I(A^2)*I(B^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;               Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    \n#&gt; A              1  75.196  75.196  94.1952 7.395e-08 ***\n#&gt; B              1 194.702 194.702 243.8964 1.097e-10 ***\n#&gt; I(A^2)         1 101.355 101.355 126.9638 1.017e-08 ***\n#&gt; I(B^2)         1   3.551   3.551   4.4479   0.05216 .  \n#&gt; A:B            1 216.931 216.931 271.7423 5.087e-11 ***\n#&gt; A:I(A^2)       1   0.235   0.235   0.2945   0.59530    \n#&gt; B:I(A^2)       1   1.046   1.046   1.3106   0.27022    \n#&gt; I(A^2):I(B^2)  1   0.490   0.490   0.6142   0.44542    \n#&gt; Residuals     15  11.974   0.798                       \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo we can finally state that a proper model would be Y ~ A*B+I(A^2):\n\nfpccd %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Y ~ A * B + I(A^2), data = .)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.64925 -0.60624  0.00919  0.65165  1.67506 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0156     0.3061   3.318  0.00362 ** \n#&gt; A             1.9390     0.2134   9.088 2.40e-08 ***\n#&gt; B             3.1201     0.2134  14.624 8.59e-12 ***\n#&gt; I(A^2)        2.9905     0.2834  10.552 2.20e-09 ***\n#&gt; A:B           4.2518     0.2754  15.437 3.32e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9541 on 19 degrees of freedom\n#&gt; Multiple R-squared:  0.9714, Adjusted R-squared:  0.9654 \n#&gt; F-statistic: 161.5 on 4 and 19 DF,  p-value: 2.191e-14"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#save-toload-from-a-file",
    "href": "posts/004-adas.utils/index.html#save-toload-from-a-file",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "Once the design matrix is prepared, you typically want to save it to a file and use it for collecting data form experiments. You can use the write.csv function, but it is recommended to use the fp_write_csv function, which will also save the design matrix properties as comments:\n\ndm &lt;-  fp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;% \n  fp_add_scale(A=c(2, 12), B=c(40, 60), suffix=\"_s\") %&gt;%\n  fp_write_csv(\"design_matrix.csv\")\n\nNote that the fp_write_csv function invisibly returns the same design matrix, so you can use it in a pipe chain. Also, the CVS files has the rows arranged in the same order as the RunOrder column (i.e. randomized).\nOnce the CSV file has been completed, you can load it back into R using the fp_read_csv function:\n\ndm &lt;- dm %&gt;% \n  fp_read_csv(\"design_matrix.csv\")\n\nNote that fp_read_csv returns the design matrix reordered according to Yates’ standard order."
  },
  {
    "objectID": "posts/004-adas.utils/index.html#fractional-factorial-plan",
    "href": "posts/004-adas.utils/index.html#fractional-factorial-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "It is possible to divide a design matrix into a fractional factorial plan using the fp_fraction function. The fraction uses a defining relationship (dr) as \\(I=ABCD\\), which is mapped in R as a one side formula ~A*B*C*D.\nAny fraction is added to the factorial.plan object in the fraction attribute.\nA full \\(2^n\\) factorial plan can be reduced to a fractional factorial plan \\(2^{n-p}\\) by applying the fp_fraction function \\(p\\) times. For example, to get a \\(2^{5-2}\\) plan with the defining relationships \\(I=ABCD\\) and \\(I=BCDE\\):\n\nfp_design_matrix(5) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_fraction(~B*C*D*E)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C * D * E \n#&gt;  Factors:  A B C D E \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABCD I=BCDE \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 12\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C     D     E Y      ABCD  BCDE\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1        1        8 (1)        1    -1    -1    -1    -1    -1 NA        1     1\n#&gt; 2        7       14 bc         1    -1     1     1    -1    -1 NA        1     1\n#&gt; 3       11        6 bd         1    -1     1    -1     1    -1 NA        1     1\n#&gt; 4       13        4 cd         1    -1    -1     1     1    -1 NA        1     1\n#&gt; 5       20       24 abe        1     1     1    -1    -1     1 NA        1     1\n#&gt; 6       22       29 ace        1     1    -1     1    -1     1 NA        1     1\n#&gt; 7       26        2 ade        1     1    -1    -1     1     1 NA        1     1\n#&gt; 8       32       22 abcde      1     1     1     1     1     1 NA        1     1\n\nNote that with the remove option you can control if you want to keep both fractions, and later on filter(ABC==1) them out.\n\nfp_design_matrix(3) %&gt;% \n  fp_fraction(~A*B*C, remove=FALSE)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABC \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C Y       ABC\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;\n#&gt; 1        1        2 (1)        1    -1    -1    -1 NA       -1\n#&gt; 2        2        5 a          1     1    -1    -1 NA        1\n#&gt; 3        3        4 b          1    -1     1    -1 NA        1\n#&gt; 4        4        8 ab         1     1     1    -1 NA       -1\n#&gt; 5        5        1 c          1    -1    -1     1 NA        1\n#&gt; 6        6        7 ac         1     1    -1     1 NA       -1\n#&gt; 7        7        3 bc         1    -1     1     1 NA       -1\n#&gt; 8        8        6 abc        1     1     1     1 NA        1\n\nAlso, note that the remove option is sticky, so that when you can apply the fp_fraction function multiple times and the first time has the option set to remove=FALSE, then all the following fp_fraction calls will have the same option set to FALSE. Setting remove=FALSE to any of the following calls can have unexpected behavior."
  },
  {
    "objectID": "posts/004-adas.utils/index.html#alias-structure",
    "href": "posts/004-adas.utils/index.html#alias-structure",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "Any fraction of a factorial plan results in a set of aliases among effects. The package provides the following functions to deal with alias structures:\n\nfp_alias_matrix: returns a matrix with the alias structure of the factors in the design matrix. The alias matrix has a plot method.\nfp_all_drs: given a set of defining relationships, returns the dependent one.\nfp_merge_drs: given a set of defining relationships, returns the merged one, i.e. the one having all the factors.\nfp_gen2alias: given a generator (i.e. the right side of a DR) and an effect name as strings, calculates the resulting alias.\n\nFor example:\n\n(am &lt;- fp_alias_matrix(~A*B*C, ~B*C*D))\n#&gt; Defining relationships:\n#&gt;  I=ABC I=BCD I=AD \n#&gt; \n#&gt;      A B AB C AC BC ABC D AD BD ABD CD ACD BCD ABCD\n#&gt; A    0 0  0 0  0  1   0 3  0  0   0  0   0   0    2\n#&gt; B    0 0  0 0  1  0   0 0  0  0   3  2   0   0    0\n#&gt; AB   0 0  0 1  0  0   0 0  0  3   0  0   2   0    0\n#&gt; C    0 0  1 0  0  0   0 0  0  2   0  0   3   0    0\n#&gt; AC   0 1  0 0  0  0   0 0  0  0   2  3   0   0    0\n#&gt; BC   1 0  0 0  0  0   0 2  0  0   0  0   0   0    3\n#&gt; ABC  0 0  0 0  0  0   0 0  2  0   0  0   0   3    0\n#&gt; D    3 0  0 0  0  2   0 0  0  0   0  0   0   0    1\n#&gt; AD   0 0  0 0  0  0   2 0  0  0   0  0   0   1    0\n#&gt; BD   0 0  3 2  0  0   0 0  0  0   0  0   1   0    0\n#&gt; ABD  0 3  0 0  2  0   0 0  0  0   0  1   0   0    0\n#&gt; CD   0 2  0 0  3  0   0 0  0  0   1  0   0   0    0\n#&gt; ACD  0 0  2 3  0  0   0 0  0  1   0  0   0   0    0\n#&gt; BCD  0 0  0 0  0  0   3 0  1  0   0  0   0   0    0\n#&gt; ABCD 2 0  0 0  0  3   0 1  0  0   0  0   0   0    0\n\n\nam %&gt;% plot()\n\n\n\n\n\n\n\n\nThe design matrix can be converted to a tibble thanks to the proper as_tibble.design.matrix S3 method:\n\nam %&gt;% as_tibble()\n#&gt; # A tibble: 42 × 3\n#&gt;    Effect.x Effect.y generator\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    \n#&gt;  1 A        BC       ABC      \n#&gt;  2 A        D        AD       \n#&gt;  3 A        ABCD     BCD      \n#&gt;  4 B        AC       ABC      \n#&gt;  5 B        ABD      AD       \n#&gt;  6 B        CD       BCD      \n#&gt;  7 AB       C        ABC      \n#&gt;  8 AB       BD       AD       \n#&gt;  9 AB       ACD      BCD      \n#&gt; 10 C        AB       ABC      \n#&gt; # ℹ 32 more rows"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#plotting",
    "href": "posts/004-adas.utils/index.html#plotting",
    "title": "Introducing the adas.utils package",
    "section": "Plotting",
    "text": "Plotting\n\nNormal probability plot\nThe normal probability plot is provided as an alternative to the quantile-quantile plot:\n\ndf &lt;- tibble(\n  xn = rnorm(100, mean=20, sd=5),\n  xu = runif(100, min=0, max=40)\n)\n\ndf %&gt;% normplot(xn)\n\n\n\n\n\n\n\ndf %&gt;% normplot(xu)\n\n\n\n\n\n\n\n\n\n\nPareto chart\nThe Pareto chart is a bar chart that displays the relative importance of problems in a format that is very easy to interpret. The bars are sorted in descending order, and the cumulative percentage of the total is shown by the line.\nIt can prove useful in the context of factorial plans, to identify the most important factors, or in sensitivity analysis, to identify the most important parameters.\nThe package provides a generic function, pareto_chart, that can be used with a tibble (or a data frame), or with a linear model (an lm object). In the latter case, the function produces the Pareto chart of the model effects.\nFor the general case, when you have a tibble with values and names:\n\nset.seed(1)\ntibble(\n  val=rnorm(10, sd=5),\n  cat=LETTERS[1:length(val)]\n  ) %&gt;%\n  pareto_chart(labels=cat, values=val)\n\n\n\n\n\n\n\n\nFor the case of a linear model:\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  pareto_chart()\n\n\n\n\n\n\n\n\n\n\nDaniel’s plot\nIn case of non-replicated factorial plans, the Daniel’s plot can be used to identify the most important factors: a quantile-quantile plot of the factors effects shows the significant factors and interactions off the diagonal.\n\ndaniel_plot_qq(lm(Y~A*B*C*D, data=filtration))\n\n\n\n\n\n\n\n\nIf you prefer, you can rather use a half-normal plot:\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  daniel_plot_hn(nlab=6, repel=TRUE)\n\n\n\n\n\n\n\n\nIt shows that none of the effects containing the B factor are significant, so we can reduce the model to Y~A*C*D:\n\nfiltration %&gt;% \n  lm(Y~A*C*D, data=.) %&gt;%\n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1 1870.56 1870.56 83.3677 1.667e-05 ***\n#&gt; C          1  390.06  390.06 17.3844 0.0031244 ** \n#&gt; D          1  855.56  855.56 38.1309 0.0002666 ***\n#&gt; A:C        1 1314.06 1314.06 58.5655 6.001e-05 ***\n#&gt; A:D        1 1105.56 1105.56 49.2730 0.0001105 ***\n#&gt; C:D        1    5.06    5.06  0.2256 0.6474830    \n#&gt; A:C:D      1   10.56   10.56  0.4708 0.5120321    \n#&gt; Residuals  8  179.50   22.44                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nEven better, the model can be further reduced to Y~A*C+A*D. Compare this conclusion with the last Pareto chart above."
  },
  {
    "objectID": "posts/001-opening/001-opening.html",
    "href": "posts/001-opening/001-opening.html",
    "title": "Opening!",
    "section": "",
    "text": "The Users Group is instantiated\n\n\n\n\n\nAn important milestone\n\n\nOn Feb. 5th, 2025, Giuseppe Espa, Maria Michela Dickson, Flavio Santi, Diego Giuliani and Paolo Bosetti had the first founding meeting of the R-Trento Users Group.\n\nRTUG &lt;- list(\"Giuseppe\", \"Maria Michela\", \"Flavio\", \"Diego\", \"Paolo\")\n\nThat’s a milestone."
  },
  {
    "objectID": "posts/002-logo/index.html",
    "href": "posts/002-logo/index.html",
    "title": "New Logo",
    "section": "",
    "text": "We have a new group logo\n\n\n\n\n\nRTUG logo\n\n\nThe new RTUG logo is a hexagon, on the style of Tidyverse packages, it takes the colors of Trentino Province lettering, and of course it incorporates the GNU-R language logo."
  },
  {
    "objectID": "posts/007-r-consortium/index.html",
    "href": "posts/007-r-consortium/index.html",
    "title": "R-Consortium supporting RTUG",
    "section": "",
    "text": "We’re supported by the R-Consortium\n\n\n\n\n\nAn important milestone\n\n\nToday, March 28th, 2025, we are proud to announce that the R-Trento Users Group has been accepted by the R-Consortium. This means that we are now officially recognized as a community of R users and developers, and we will receive support from the R-Consortium for our activities.\nWe thank the R-Consortium for the financial support that will allow us to organize our first in-person meeting in the next months and to have our meeting announcements published on ."
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html",
    "title": "Tukey vs. Student",
    "section": "",
    "text": "Packages that we need\n\n\n\nIn this example, we are using the packages tidyverse and adas.utils version 1.1.4 (see https://github.com/pbosetti/adas.utils)\n\nlibrary(tidyverse)\nlibrary(adas.utils)"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#the-dataset",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#the-dataset",
    "title": "Tukey vs. Student",
    "section": "The dataset",
    "text": "The dataset\nLet us compare the result of a Tukey’s test with a repeated Student’s T-test on all combinations. We consider the cotton dataset, which is included in the adas.utils package from version 1.1.4. The dataset contains the tensile strength of mixed cotton-synthetic yarns with different cotton content:\n\ncotton %&gt;% \n  ggplot(aes(x=Cotton, y=Strength, group=Cotton)) +\n  geom_boxplot()"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#inference-on-strength",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#inference-on-strength",
    "title": "Tukey vs. Student",
    "section": "Inference on Strength",
    "text": "Inference on Strength\nNow we want to compare all the possibile combinations of treatmentswith a set of pairwise T-tests.\nFirst, we create the list of pairwise combinations, sorting each pair in descending order, as it is done by the TukeyHSD function:\n\nlvl &lt;- levels(cotton$Cotton) %&gt;% \n  combn(2, FUN=sort, decreasing=T) %&gt;% \n  as_tibble(.name_repair=\"minimal\") %&gt;% \n  as.list() %&gt;% glimpse()\n\nList of 10\n $ : chr [1:2] \"20\" \"15\"\n $ : chr [1:2] \"25\" \"15\"\n $ : chr [1:2] \"30\" \"15\"\n $ : chr [1:2] \"35\" \"15\"\n $ : chr [1:2] \"25\" \"20\"\n $ : chr [1:2] \"30\" \"20\"\n $ : chr [1:2] \"35\" \"20\"\n $ : chr [1:2] \"30\" \"25\"\n $ : chr [1:2] \"35\" \"25\"\n $ : chr [1:2] \"35\" \"30\"\n\n\nNow, for each pair we do a T-test on the corresponding cotton data-frame subset, and accumulate into a new tibble the values of interest. We get the df table that is analogous to the TukeyHSD output:\n\ndf &lt;- lvl %&gt;% reduce(\\(acc, pair) {\n  tt &lt;- cotton %&gt;% \n    filter(Cotton %in% pair) %&gt;% \n    t.test(Strength~Cotton, data=., var.equal=TRUE)\n  bind_rows(acc, list(\n    pair = paste0(pair[1], \"-\", pair[2]),\n    diff = -median(tt$conf.int),\n    lwr = -tt$conf.int[2],\n    upr = -tt$conf.int[1],\n    p.value = tt$p.value\n  ))\n}, .init=tibble()) \n\ndf %&gt;% knitr::kable()\n\n\n\n\npair\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\n5.6\n0.8740978\n10.3259022\n0.0257453\n\n\n25-15\n7.8\n3.7398608\n11.8601392\n0.0021967\n\n\n30-15\n11.8\n7.4246648\n16.1753352\n0.0002541\n\n\n35-15\n1.0\n-3.5423014\n5.5423014\n0.6253800\n\n\n25-20\n2.2\n-1.6724395\n6.0724395\n0.2265324\n\n\n30-20\n6.2\n1.9982605\n10.4017395\n0.0093233\n\n\n35-20\n-4.6\n-8.9753352\n-0.2246648\n0.0415629\n\n\n30-25\n4.0\n0.5641312\n7.4358688\n0.0277266\n\n\n35-25\n-6.8\n-10.4461127\n-3.1538873\n0.0026133\n\n\n35-30\n-10.8\n-14.7941163\n-6.8058837\n0.0002496\n\n\n\n\n\nTo be compared with Tukey’s values:\n\nttdf &lt;- TukeyHSD(aov(lm(Strength~Cotton, data=cotton)))$Cotton %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(var=\"pair\") %&gt;% \n  rename(p.value=`p adj`)\nttdf %&gt;% knitr::kable()\n\n\n\n\npair\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\n5.6\n0.2270417\n10.9729583\n0.0385024\n\n\n25-15\n7.8\n2.4270417\n13.1729583\n0.0025948\n\n\n30-15\n11.8\n6.4270417\n17.1729583\n0.0000190\n\n\n35-15\n1.0\n-4.3729583\n6.3729583\n0.9797709\n\n\n25-20\n2.2\n-3.1729583\n7.5729583\n0.7372438\n\n\n30-20\n6.2\n0.8270417\n11.5729583\n0.0188936\n\n\n35-20\n-4.6\n-9.9729583\n0.7729583\n0.1162970\n\n\n30-25\n4.0\n-1.3729583\n9.3729583\n0.2101089\n\n\n35-25\n-6.8\n-12.1729583\n-1.4270417\n0.0090646\n\n\n35-30\n-10.8\n-16.1729583\n-5.4270417\n0.0000624\n\n\n\n\n\nNow let’s join both tables and make a common plot:\n\ncompared &lt;- df %&gt;% \n  left_join(ttdf, by=join_by(pair), suffix=c(\".student\", \".tukey\")) %&gt;% \n  pivot_longer(-pair, names_to = c(\"stat\", \"test\"), names_pattern = \"(.*)\\\\.(student|tukey)$\") %&gt;% \n  pivot_wider(names_from = stat)\n\ncompared %&gt;% knitr::kable()\n\n\n\n\npair\ntest\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\nstudent\n5.6\n0.8740978\n10.3259022\n0.0257453\n\n\n20-15\ntukey\n5.6\n0.2270417\n10.9729583\n0.0385024\n\n\n25-15\nstudent\n7.8\n3.7398608\n11.8601392\n0.0021967\n\n\n25-15\ntukey\n7.8\n2.4270417\n13.1729583\n0.0025948\n\n\n30-15\nstudent\n11.8\n7.4246648\n16.1753352\n0.0002541\n\n\n30-15\ntukey\n11.8\n6.4270417\n17.1729583\n0.0000190\n\n\n35-15\nstudent\n1.0\n-3.5423014\n5.5423014\n0.6253800\n\n\n35-15\ntukey\n1.0\n-4.3729583\n6.3729583\n0.9797709\n\n\n25-20\nstudent\n2.2\n-1.6724395\n6.0724395\n0.2265324\n\n\n25-20\ntukey\n2.2\n-3.1729583\n7.5729583\n0.7372438\n\n\n30-20\nstudent\n6.2\n1.9982605\n10.4017395\n0.0093233\n\n\n30-20\ntukey\n6.2\n0.8270417\n11.5729583\n0.0188936\n\n\n35-20\nstudent\n-4.6\n-8.9753352\n-0.2246648\n0.0415629\n\n\n35-20\ntukey\n-4.6\n-9.9729583\n0.7729583\n0.1162970\n\n\n30-25\nstudent\n4.0\n0.5641312\n7.4358688\n0.0277266\n\n\n30-25\ntukey\n4.0\n-1.3729583\n9.3729583\n0.2101089\n\n\n35-25\nstudent\n-6.8\n-10.4461127\n-3.1538873\n0.0026133\n\n\n35-25\ntukey\n-6.8\n-12.1729583\n-1.4270417\n0.0090646\n\n\n35-30\nstudent\n-10.8\n-14.7941163\n-6.8058837\n0.0002496\n\n\n35-30\ntukey\n-10.8\n-16.1729583\n-5.4270417\n0.0000624\n\n\n\n\n\n\ncompared %&gt;%\n  ggplot(aes(x=diff, y=pair, color=test)) + \n  geom_point() + \n  geom_errorbar(aes(xmin=lwr, xmax=upr), width=0.5, position=position_dodge()) + \n  geom_vline(xintercept=0, color=\"red\") +\n  labs(x=\"Difference\", y=\"Pair\", title=\"95% pairwise confidence level\")"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#the-family-wise-error-rate",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#the-family-wise-error-rate",
    "title": "Tukey vs. Student",
    "section": "The Family-Wise Error Rate",
    "text": "The Family-Wise Error Rate\n\n\n\n\n\n\nThe Family-Wise Error Rate\n\n\n\nAs expected, the Tukey’s test in the last plot shows larger confidence intervals, that is, it has reduced chances of a false positive (Type I Error). More specifically, Tukey’s test controls the family-wise error rate (FWER) — the probability of making any false positive in the full set of comparisons.\n\n\nLet’s see why. If we set a confidence level of 0.95, it means that the probability of not making a Type I error on a single T-test is 0.95.\nFor 3 independent tests, the probability of no Type I error at all (in any of the tests) is: \\[\n0.95^3 \\approx 0.857\n\\] So the chance of making at least one Type I error is: \\[\n1 - 0.95^3 \\approx 0.143 \\quad \\text{(14.3\\%)}\n\\] That’s almost triple the risk you thought you were accepting! Furthermore, this risk increases exponentially with the number of comparisons. Given \\(n\\) elements, the number of possible combinations of \\(k\\) elements is given by the binomial coefficient: \\[\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\] In R, the latter is provided by the choose(n, k) function:\n\nchoose(5, 2)\n\n[1] 10\n\n\nso, with increasing number of classes to be compared, this is what happens to the probability of committing at least one Type-I error:\n\n2:15 %&gt;% reduce(\\(acc, k) {\n    nt &lt;- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-0.95^nt)\n    )\n  }, .init=tibble()) %&gt;% \n  ggplot(aes(x=n, y=p)) +\n  geom_point() +\n  geom_line() +\n  ylim(0, 1) +\n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\")\n\n\n\n\n\n\n\n\nAnd what happens if we change the confidence level? Let’s see, by creating a parametric plot similar to the ast one, but with different confidence levels. First we factor the last reduce opration into a function, FWER, that takes the confidence level as an argument. The function returns a tibble with the number of classes and the corresponding probability of Type I error.\n\nFWER &lt;- function(levels, conf.int=0.95) {\n  reduce(levels, \\(acc, k) {\n    nt &lt;- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-conf.int^nt)\n    )\n  }, .init=tibble()) \n}\n\nThen we apply the FWER function to a set of confidence levels, and join the results into a single tibble via the usual reduce, and finally, we plot the results:\n\ncl &lt;- c(0.9, 0.95, 0.99, 0.995, 0.999) \nN &lt;- 2:15\ncl %&gt;% \n  reduce(\\(acc, ci) {\n    fwer &lt;- FWER(N, ci) %&gt;% rename(!!paste0(\"cl-\", ci):=p)\n    left_join(acc, fwer, by=join_by(n))\n  }, .init=tibble(n=N)) %&gt;% \n  pivot_longer(-n, names_to = c(NA, \"cl\"), names_pattern=\"(cl-)(.*)\") %&gt;% \n  ggplot(aes(x=n, y=value, color=cl)) + \n  geom_point() + \n  geom_line() + \n  ylim(0, 1) + \n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\", \n    color=\"Conf. level\")\n\n\n\n\n\n\n\n\n\nThat’s all, folks!"
  },
  {
    "objectID": "meetings/25.1-meeting.html",
    "href": "meetings/25.1-meeting.html",
    "title": "First RTUG meeting",
    "section": "",
    "text": "The first R-Trento Users Meeting, code RTUG::25.1, is planned for Friday, May 30, 2025 at 14:30 in the Aula Rossa of the Department of Economics and Management, via Inama 5, Trento.\nParticipation is free but you need to subscribe to the event via ."
  },
  {
    "objectID": "meetings/25.1-meeting.html#topics",
    "href": "meetings/25.1-meeting.html#topics",
    "title": "First RTUG meeting",
    "section": "Topics",
    "text": "Topics\n\nWelcome and introduction to the R-Trento Users Group (P. Bosetti)\nR in teaching (R. Micciolo and G. Espa)\nadas.utils package: Design of Experiments, the tidy way (P. Bosetti)\nE-Agle Trento Racing Team: reporting racecar test results with RStudio (E-Agle TRT)\nRefreshments and networking!"
  },
  {
    "objectID": "meetings/25.1-meeting.html#venue",
    "href": "meetings/25.1-meeting.html#venue",
    "title": "First RTUG meeting",
    "section": "Venue",
    "text": "Venue\nAula Rossa of the Department of Economics and Management, via Inama 5, Trento.\n\n\n\n\n\n\nEvent flyer\n\n\n\nDownload here the event flyer."
  },
  {
    "objectID": "bibliography.html",
    "href": "bibliography.html",
    "title": "Bibliography",
    "section": "",
    "text": "Members of RTUG have contributed to the following topics:\n\n CRAN Packages\n\nADAS Utils—Design of Experiments\nnoisyCE2—Cross-Entropy Optimisation of Noisy Functions\nRMAWGEN—Multi-Site Auto-Regressive Weather GENerator\ngeotopbricks—An R Plug-in for the Distributed Hydrological Model GEOtop\n\n\n\n\n\n\n\n\n\n Books\n\nAgresti A., C. Franklin, B. Klingenberg (2025) Statistica — l’arte e la scienza d’imparare dai dati (quinta edizione), Pearson Italia, Milano (a cura di G. Espa, R. Micciolo, D. Giuliani, M.M. Dickson). ISBN: 9788891931894.\nBosetti, P. (2022) Fondamenti di statistica — Per le misure e l’analisi dati in ambito industriale. Con esempi in GNU-R. Libreriauniversitaria.it. ISBN: 978-8833595188.\nMicciolo R., L. Canal, G. Espa (2021) Probabilità e modelli – Teoria e pratica con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 978-88-916-4935-5.\nEspa G., R. Micciolo (2014) Problemi ed Esperimenti di Statistica con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838786105.\nBee M, F. Santi (2013) Finanza quantitativa con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838787041.\nR. Micciolo, G. Espa, L. Canal (2013) Ricerca con R – Metodi di inferenza statistica, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838787003.\nEspa G., R. Micciolo (2012) Analisi esplorativa dei dati con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN 8838786853.\n\n\n\n Papers\n\nSanti F., M.M. Dickson, G. Espa, D. Giuliani (2022) plot3logit: Ternary Plots for Interpreting Trinomial Regression Models, Journal of Statistical Software, Code Snippets, 103 (1), 1–27. DOI: 10.18637/jss.v103.c01.\nGiuliani D., M.M. Dickson, G. Espa (2015) Teaching statistics in the context of social foresight. An applied approach based on the use of an open-source software, On the Horizon, 23, 2, 140–148. DOI: 10.1108/OTH-02-2015-0010.\nCanal L., Micciolo R. (2008) The proportional means regression model for the analysis of recurrent event data. BioMedical Statistics and Clinical Epidemiology, 2:2, 157-169 (pdf here).\nCanal L., Micciolo R. (2014) The chi-square controversy: what if Pearson had R?. Journal of Statistical Computation and Simulation, 84:5, 1015-1021. DOI: 10.1080/00949655.2012.737793\nDecarli A., La Vecchia C., Malvezzi M., Micciolo R. (2014) An R package for fitting age, period and cohort models. Epidemiology Biostatistics and Public Health, 11:4, e9977-1 – e9977-12. DOI: 10.2427/9977 (pdf here).\nFedrizzi G., Canal L., Micciolo R. (2022). UEFA EURO 2020: An exciting match between football and probability. Teaching Statistics, 44:3, 119-125. DOI: 10.1111/test.12315 (pdf here)."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contacts and updates",
    "section": "",
    "text": "Email\nIf you are interested in the RTUG activities, please contact the RTUG group (rtug.group at unitn dot it).\nIf you want to inquire about this web site, please contact Paolo Bosetti (paolo.bosetti at unitn dot it).\n\n\n RSS feeds\nYou can stay updated using the following feeds:\n\n\n List of meetings\n List of posts\n\n\n\n\n More info\nMore info on the group and on this website on the about page"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R-Trento Users Group (RTUG)",
    "section": "",
    "text": "The R-Trento Users Group is a shared space for academics, scholars, students, and professionals living and working in Trentino and surrounding areas that are passionate about the R language and its suite of tools.\nThe suggested pronunciation for RTUG is “Ar-TOO(g)”, akin to the Italian “Artù”.\n\n Mission\nRTUG mission is to spread the use or R language and tools within academia, industry and public administration.\n\n\n\n\n\n How it works\nRTUG is a community-driven group. We organize meetings, workshops, and seminars, we share news, and we publish posts and tutorials. We are open to collaborations and partnerships with other groups and organizations.\nMeetings are the core of our activities: we plan to have two to three meetings per year, with a mix of invited speakers, tutorials, and member presentations. Meetings can be a great opportunity for networking, learning, sharing experiences, and possibly finding new collaborations or solution providers.\nTo collaborate with RTUG, you can:\n\nBecome a member: contact the group (rtug.group at unitn dot it?subject=%5BRTUG%5D%20Becoming%20a%20member) and ask for instructions. Membership if free and open to anyone interested. Please note that, to simplify the management of members mailing list, we are currently accepting one member per institution/department/workgroup.\nGet to know us: join our meetings\nVolunteer and advertise your R skills: contribute a post\n\n\n\n Next meeting\n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\nDescription\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nFirst RTUG meeting\n\n\nPaolo Bosetti\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n News\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTukey vs. Student\n\n\n\nR\n\ntidyverse\n\ninference\n\nTukey\n\n\n\nTo compare two samples, or groups, we can use a T-test. But if we want to compare more than two groups, we need to use Tukey’s test. In this post we investigate the reason why a Tukey’s test is more appropriate and robust than a set of pairwise T-tests for all possible combinations of groups. This is also an excuse to illustrate the power of purrr and dplyr packages, specifically for the use of map/reduce, join_left, and pivot_longer/pivot_wider functions.\n\n\n\n\n\nApr 10, 2025\n\n\nPaolo Bosetti\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nR-Consortium supporting RTUG\n\n\n\nRTUG\n\nmilestone\n\nannouncement\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nTukey’s test plot in adas.utils\n\n\n\nR\n\npackages\n\n\n\nThe new version 1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test.\n\n\n\n\n\nMar 27, 2025\n\n\nPaolo Bosetti\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nMoving to a new domain\n\n\n\nRTUG\n\nmilestone\n\n\n\nRTUG website has a new domain and a new contact email.\n\n\n\n\n\nFeb 26, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the adas.utils package\n\n\n\npackages\n\npost\n\nCRAN\n\ndesign of experiments\n\n\n\nThe package adas.utils, contributed by one of RTUG members, aims at helping in the design and analysis of factorial experiments.\n\n\n\n\n\nFeb 10, 2025\n\n\nPaolo Bosetti\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nLogarithmic scales in GGPlot2\n\n\n\npost\n\nR\n\ntidyverse\n\nGGPlot2\n\nsignal analysis\n\n\n\nWith the excuse of doing signal analysis in R, this post discusses on how to deal with logarithmic scales and tick-marks in GGPlot2, and how to generate log-spaced grids to have an equally dense set of points in the resulting plot.\n\n\n\n\n\nFeb 9, 2025\n\n\nPaolo Bosetti\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nNew Logo\n\n\n\nRTUG\n\nwebsite\n\nannouncement\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nOpening!\n\n\n\nRTUG\n\nmilestone\n\nannouncement\n\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\nNo matching items\n\n\n\n On Bluesky\n\n\n\n\n\n\nLast post:\n\n\n\n\nLoading last post"
  }
]