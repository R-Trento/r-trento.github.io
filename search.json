[
  {
    "objectID": "posts/001-opening/001-opening.html",
    "href": "posts/001-opening/001-opening.html",
    "title": "Opening!",
    "section": "",
    "text": "The Users Group is instantiated\n\n\n\n\n\nAn important milestone\n\n\nOn Feb. 5th, 2025, Giuseppe Espa, Maria Michela Dickson, Flavio Santi, Diego Giuliani and Paolo Bosetti had the first founding meeting of the R-Trento Users Group.\n\nRTUG &lt;- list(\"Giuseppe\", \"Maria Michela\", \"Flavio\", \"Diego\", \"Paolo\")\n\nThat’s a milestone."
  },
  {
    "objectID": "posts/007-r-consortium/index.html",
    "href": "posts/007-r-consortium/index.html",
    "title": "R-Consortium supporting RTUG",
    "section": "",
    "text": "We’re supported by the R-Consortium\n\n\n\n\n\nAn important milestone\n\n\nToday, March 28th, 2025, we are proud to announce that the R-Trento Users Group has been accepted by the R-Consortium. This means that we are now officially recognized as a community of R users and developers, and we will receive support from the R-Consortium for our activities.\nWe thank the R-Consortium for the financial support that will allow us to organize our first in-person meeting in the next months and to have our meeting announcements published on ."
  },
  {
    "objectID": "posts/003-logscale/index.html",
    "href": "posts/003-logscale/index.html",
    "title": "Logarithmic scales in GGPlot2",
    "section": "",
    "text": "Rationale\nRecently I had to port in R some Matlab code using the tf and bode functions, which are respectively used to calculate the transfer function and create a Bode plot of it.\nThe R package control luckily provides the analogous functions, although its control::bodeplot function uses the base plot interface. Of course, I wanted to make an analogous plot with GGplot2 tools.\n\n\nExample: vibration isolation\nLet us use the example for a lumped parameters model of a vibration isolation system, that is, a 1-DoF mass-spring-damper system. Briefly, its transfer function can be created as:\n\nM &lt;- 10\nK &lt;- 1000\nC &lt;- 50\n\n(H &lt;- tf(c(C/K, 1),c(M/K, C/K, 1)))\n\n\ny1:\n        0.05 s^1 + 1 \n  - - - - - - - - - - - - -\n    0.01 s^2 + 0.05 s + 1 \n\n\nTransfer Function: Continuous time model \n\n\nIts Bode representation can be obtained by:\n\nbode(H) %&gt;% str()\n\nList of 3\n $ w    : num [1:10000] 0 0.01 0.02 0.03 0.04 ...\n $ mag  : num [1:10000] 0.00 8.69e-06 3.48e-05 7.82e-05 1.39e-04 ...\n $ phase: num [1:10000] 0.00 -2.87e-08 -2.29e-07 -7.74e-07 -1.83e-06 ...\n\n\nThat is, a list of three vectors reporting frequency (w), magnitude in dB (mag), and phase in degrees (phase). Why the control developers decided to return a list of equally sized vectors rather a data frame is beyond me, but let’s deal with what we have.\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;% \n  head() %&gt;% \n  knitr::kable()\n\n\n\n\nfrequency (rad/s)\nmagnitude (dB)\nphase (deg)\n\n\n\n\n1\n0.0870762\n-0.0288644\n\n\n2\n0.3509189\n-0.2362699\n\n\n3\n0.7993794\n-0.8294252\n\n\n4\n1.4452744\n-2.0825653\n\n\n5\n2.3044892\n-4.3987054\n\n\n6\n3.3880407\n-8.4155907\n\n\n\n\n\nTo make the Bode plot, which reports magnitude vs. frequency on top of phase vs. frequency, we make the tibble tidy and use facet_wrap:\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10()\n\n\n\n\n\n\n\n\nNote the followings:\n\nin facet_wrap, we use the option scales=\"free\": this allows to independently rescale the axes of each facet;\nthe horizontal axis is logarithmic, but there is only one secondary grid line, while we usually have secondary gridlines at 2, 3, …, 9;\nthe point density is not evenly spaced on the logarithmic axis.\n\nSo, here we want to tackle the problems in 2. and 3..\n\n\nLog-tickmarks: Solution\nThe scale_x_log10() function allows to specify the breaks and the minor_breaks, which we can exploit to fix the gridlines. How can we get a log-spaced sequence? an elegant solution uses the outer product %o% of two vectors: that of the ticks, and that of the orders of magnitude (ooms):\n\nticks &lt;- 2:9\nooms &lt;- 10^seq(0, 4)\n\nticks %o% ooms\n\n     [,1] [,2] [,3] [,4]  [,5]\n[1,]    2   20  200 2000 20000\n[2,]    3   30  300 3000 30000\n[3,]    4   40  400 4000 40000\n[4,]    5   50  500 5000 50000\n[5,]    6   60  600 6000 60000\n[6,]    7   70  700 7000 70000\n[7,]    8   80  800 8000 80000\n[8,]    9   90  900 9000 90000\n\n\nLooking at the columns , in sequence, we have what we want, so:\n\n(breaks &lt;- as.vector(ticks %o% ooms))\n\n [1]     2     3     4     5     6     7     8     9    20    30    40    50\n[13]    60    70    80    90   200   300   400   500   600   700   800   900\n[25]  2000  3000  4000  5000  6000  7000  8000  9000 20000 30000 40000 50000\n[37] 60000 70000 80000 90000\n\n\n\nbode(H, w=1:1e4) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10(minor_breaks=breaks, labels=scales::scientific)\n\n\n\n\n\n\n\n\nBingo!\nNow, we still have too sparse points to the left, and definitely too many points to the right. We can use a similar approach to define the frequency vector.\n\n\nLog-spaced points: Solution\nWe use the same outer product trick, multiplying the vector of orders of magnitude by a vector of positions, exponentially spaced within each magnitude:\n\npts &lt;- 10^seq(0, 1, 0.1) %&gt;% tail(-1)\n(freqs &lt;- as.vector(pts %o% ooms)) %&gt;% head(n=20)\n\n [1]   1.258925   1.584893   1.995262   2.511886   3.162278   3.981072\n [7]   5.011872   6.309573   7.943282  10.000000  12.589254  15.848932\n[13]  19.952623  25.118864  31.622777  39.810717  50.118723  63.095734\n[19]  79.432823 100.000000\n\n\nFinally:\n\npts &lt;- 10^seq(0, 1, 0.01) %&gt;% tail(-1)\nfreqs &lt;- as.vector(pts %o% ooms)\n\nbode(H, w=freqs) %&gt;% {\n  tibble(\n    `frequency (rad/s)` = .$w, \n    `magnitude (dB)` = .$mag,\n    `phase (deg)` = .$phase\n  )\n} %&gt;%\n  pivot_longer(-`frequency (rad/s)`) %&gt;% \n  ggplot(aes(x=`frequency (rad/s)`, y=value)) +\n  geom_line() +\n  geom_point(alpha = 0.2) +\n  facet_wrap(~name, nrow=2, scales=\"free\") +\n  scale_x_log10(minor_breaks=breaks, labels=scales::scientific)\n\n\n\n\n\n\n\n\n\n\nPutting all together\nWe can then put everything together and make a useful function (note that we are now converting the frequencies to Hz):\n\nggbodeplot &lt;- function(tf, fmin=1, fmax=1e4, df=0.01) {\n  ticks &lt;- 2:9\n  pts &lt;- 10^seq(0, 1, df) %&gt;% tail(-1)\n  ooms &lt;- 10^(floor(log10(fmin)):ceiling(log10(fmax)-1))\n  breaks &lt;- as.vector(ticks %o% ooms)\n  freqs &lt;- as.vector(pts %o% ooms)\n  \n  bode(tf, freqs*2*pi) %&gt;% {\n    tibble(f=.$w/(2*pi), `magnitude (dB)`=.$mag, `phase (deg)`=.$phase)} %&gt;% \n    pivot_longer(-f) %&gt;% \n    ggplot(aes(x=f, y=value)) +\n    geom_line() +\n    scale_x_log10(minor_breaks=breaks, labels=scales::scientific) +\n    facet_wrap(~name, nrow=2, scales=\"free\") +\n    labs(x=\"frequency (Hz)\")\n}\n\nH %&gt;% ggbodeplot(fmin=0.1, fmax=100)\n\n\n\n\n\n\n\n\n\n\nOne last thing…\nWell, the above is mostly of academic interest, at least for what pertains the logarithmic grid lines: it shows a nice and useful way for creating regularly spaced vectors, which is really useful to evenly distribute abscissa values when the axis scale is not linear. But thanks to the scales package there is a quick way for having any axis, whichever the scale, with a number of minor breaks different to 1 (the defaiult in GGplot). In fact, we can just use the scales::minor_breaks_n() function to generate minor grid lines at will:\n\nggbodeplot &lt;- function(tf, fmin=1, fmax=1e4, df=0.01) {\n  pts &lt;- 10^seq(0, 1, df) %&gt;% tail(-1)\n  ooms &lt;- 10^(floor(log10(fmin)):ceiling(log10(fmax)-1))\n  freqs &lt;- as.vector(pts %o% ooms)\n  \n  bode(tf, freqs*2*pi) %&gt;% {\n    tibble(f=.$w/(2*pi), `magnitude (dB)`=.$mag, `phase (deg)`=.$phase)} %&gt;% \n    pivot_longer(-f) %&gt;% \n    ggplot(aes(x=f, y=value)) +\n    geom_line() +\n    scale_x_log10(\n      minor_breaks=scales::minor_breaks_n(10), \n      labels= ~ latex2exp::TeX(paste0(\"$10^{\", log10(.), \"}$\"))\n    ) +\n    facet_wrap(~name, nrow=2, scales=\"free\") +\n    labs(x=\"frequency (Hz)\")\n}\n\nH %&gt;% ggbodeplot(fmin=0.1, fmax=100)\n\n\n\n\n\n\n\n\nwhere the trick is to set scale_x_log10(minor_breaks=scales::minor_breaks_n(10)). Note that the argument is the number of intervals rather than the number of grid lines (so, 10 rather than 9). As a final suggestion, try and use the same command with a scale_x_continuous: it works whichever is the axis transformation (including identity). Also, note the labels lambda function used for formatting tick labels.\n\nThat’s all, folks!"
  },
  {
    "objectID": "posts/005-domain/index.html",
    "href": "posts/005-domain/index.html",
    "title": "Moving to a new domain",
    "section": "",
    "text": "Starting from February 26, 2025, RTUG website has a new domain under the University of Trento domain: rtug.unitn.it. So the group’s homepage is now accessible as https://rtug.unitn.it.\nFurthermore, there is a new contact email address: mailto:rtug.group@unitn.it (rtug.group at unitn dot it)\n\n\n\n\n\n\nNote\n\n\n\nThe old address https://r-trento.github.io will continue to work, automatically redirecting to the new domain name.\n\n\n\nThat’s all, folks!"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides and Presentations",
    "section": "",
    "text": "This is a selection of the most interesting presentations contributed by our members.\n\n\n\n\n\n\nHow to contribute\n\n\n\nIf you want to contribute, head on to the GitHub repo, fork it, add a new post in the slides folder, tag it with the slides category and make a pull request. Use the slides/_template.qmd file to start.\n\n\n\n Presentations\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nSpatial Sampling in R\n\n1 min\n\n\nsampling\n\nmeeting\n\nrtug::25.1\n\n\n\nWe introduce the BalancedSampling package, which allows the selection of balanced and spatially balanced samples, widely used in the environmental/forestry field, with…\n\n\n\nMaria Michela Dockson\n\n\nMay 30, 2025\n\n\n\n\n\n\n\n\n\n\nrtug::25.1\n\n2 min\n\n\nintro\n\nmeeting\n\nrtug::25.1\n\n\n\nIntroductory slides to the first RTUG meeting, code rtug::25.1, held on May 30, 2025.\n\n\n\nPaolo Bosetti\n\n\nMay 30, 2025\n\n\n\n\n\n\n\n\n\n\nThe adas.utils package\n\n9 min\n\n\npackages\n\nmeeting\n\nrtug::25.1\n\n\n\nWe are here presenting the adas.utils package, a collection of functions for the design of experiments, the tidy way.\n\n\n\nPaolo Bosetti\n\n\nMay 30, 2025\n\n\n\n\n\n\n\n\n\n\nThe R Package rmf in Teaching\n\n1 min\n\n\nteaching\n\nmeeting\n\nrtug::25.1\n\n\n\nWe introduce the rmf package, which contains a series of functions developed primarily for use in educational settings, particularly in basic university statistics…\n\n\n\nRocco Micciolo, Giuseppe Espa\n\n\nMay 30, 2025\n\n\n\n\n\n\n\n\n\n\nBioinformatics and R: Visualizing Genomic Data\n\n1 min\n\n\nbioinformatics\n\nmeeting\n\nrtug::25.1\n\n\n\nAn overview of the use of R in bioinformatics, particularly its use for visualizing genomic data.\n\n\n\nYari Ciani\n\n\nMay 30, 2025\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nNote\n\n\n\n Unless otherwise specified, all content is licensed as BY-NC-SA 4.0."
  },
  {
    "objectID": "members.html",
    "href": "members.html",
    "title": "Members",
    "section": "",
    "text": "Associate professor of Mechanical and Thermal Measurements at the Department of Industrial Engineering, University of Trento.\n\n\n teaching stuff: paolobosetti.quarto.pub\n personal blog\n GitHub page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaria Michela Dickson is Full Professor of Economic Statistics at the Department of Statistical Sciences of the University of Padova.\n\n\n The Department of Statistical Sciences of the University of Padova\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGiuseppe Espa is Full Professor of Economic Statistics at the Department of Economics and Management of the University of Trento. He coordinates the research group StaTA.\n\n\n The StaTA group at University of Trento\n The CSSC research group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFull professor of Economic Statistics at the Department of Economics and Management, University of Trento.\n\n\n The StaTA group at University of Trento\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFlavio Santi is Associate Professor of Economic Statistics at the Department of Economics and Management of the University of Trento.\n\n\n Personal website\n The StaTA group at University of Trento\n GitHub code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichele Segata is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento.\n\n\n The MANTA research group web page\n Personal web page\n GitHub code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRocco Micciolo is Full Professor of Medical Statistics at the Department of Psychology and Cognitive Sciences and the Interdepartmental Centre for Medical Sciences-CISMed of the University of Trento\n\n\n DPCS\n Personal web page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYari Ciani is Assistant Professor (RTDa) at the Department of Cellular, Computational and Integrative Biology - CIBIO of the University of Trento.\n\n\n GitHub page\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhilippe Velha is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento. He is also affiliated with TIFPA - Trento Institute for Fundamental Physics and Applications.\n\n\n DISI\n TIFPA"
  },
  {
    "objectID": "members.html#paolo-bosetti",
    "href": "members.html#paolo-bosetti",
    "title": "Members",
    "section": "",
    "text": "Associate professor of Mechanical and Thermal Measurements at the Department of Industrial Engineering, University of Trento.\n\n\n teaching stuff: paolobosetti.quarto.pub\n personal blog\n GitHub page"
  },
  {
    "objectID": "members.html#maria-michela-dickson",
    "href": "members.html#maria-michela-dickson",
    "title": "Members",
    "section": "",
    "text": "Maria Michela Dickson is Full Professor of Economic Statistics at the Department of Statistical Sciences of the University of Padova.\n\n\n The Department of Statistical Sciences of the University of Padova"
  },
  {
    "objectID": "members.html#giuseppe-espa",
    "href": "members.html#giuseppe-espa",
    "title": "Members",
    "section": "",
    "text": "Giuseppe Espa is Full Professor of Economic Statistics at the Department of Economics and Management of the University of Trento. He coordinates the research group StaTA.\n\n\n The StaTA group at University of Trento\n The CSSC research group"
  },
  {
    "objectID": "members.html#diego-giuliani",
    "href": "members.html#diego-giuliani",
    "title": "Members",
    "section": "",
    "text": "Full professor of Economic Statistics at the Department of Economics and Management, University of Trento.\n\n\n The StaTA group at University of Trento"
  },
  {
    "objectID": "members.html#flavio-santi",
    "href": "members.html#flavio-santi",
    "title": "Members",
    "section": "",
    "text": "Flavio Santi is Associate Professor of Economic Statistics at the Department of Economics and Management of the University of Trento.\n\n\n Personal website\n The StaTA group at University of Trento\n GitHub code"
  },
  {
    "objectID": "members.html#michele-segata",
    "href": "members.html#michele-segata",
    "title": "Members",
    "section": "",
    "text": "Michele Segata is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento.\n\n\n The MANTA research group web page\n Personal web page\n GitHub code"
  },
  {
    "objectID": "members.html#rocco-micciolo",
    "href": "members.html#rocco-micciolo",
    "title": "Members",
    "section": "",
    "text": "Rocco Micciolo is Full Professor of Medical Statistics at the Department of Psychology and Cognitive Sciences and the Interdepartmental Centre for Medical Sciences-CISMed of the University of Trento\n\n\n DPCS\n Personal web page"
  },
  {
    "objectID": "members.html#yari-ciani",
    "href": "members.html#yari-ciani",
    "title": "Members",
    "section": "",
    "text": "Yari Ciani is Assistant Professor (RTDa) at the Department of Cellular, Computational and Integrative Biology - CIBIO of the University of Trento.\n\n\n GitHub page"
  },
  {
    "objectID": "members.html#philippe-velha",
    "href": "members.html#philippe-velha",
    "title": "Members",
    "section": "",
    "text": "Philippe Velha is tenure-track Assistant Professor at the Department of Information Engineering and Computer Science of the University of Trento. He is also affiliated with TIFPA - Trento Institute for Fundamental Physics and Applications.\n\n\n DISI\n TIFPA"
  },
  {
    "objectID": "meetings/25.1-meeting.html",
    "href": "meetings/25.1-meeting.html",
    "title": "First RTUG meeting",
    "section": "",
    "text": "The first R-Trento Users Meeting, code RTUG::25.1, is planned for Friday, May 30, 2025 at 14:30 in the Aula Rossa of the Department of Economics and Management, via Inama 5, Trento.\nParticipation is free but you need to subscribe to the event via .\nCertificates of participation will be available upon request"
  },
  {
    "objectID": "meetings/25.1-meeting.html#topics",
    "href": "meetings/25.1-meeting.html#topics",
    "title": "First RTUG meeting",
    "section": " Topics",
    "text": "Topics\n\n\n\n\n\n\n\n\nEvent flyer\n\n\n\nDownload here  the event flyer.\n\n\n\nWelcome and Introduction to the R-Trento Users Group (P. Bosetti)\nThe R Package rmf in Teaching (R. Micciolo and G. Espa)\nThe adas.utils Package: Design of Experiments, the Tidy Way (P. Bosetti)\nBioinformatics and R: Visualizing Genomic Data (Y. Ciani)\nSpatial Sampling in R (M. M. Dickson)\nRefreshments and networking!\n\nSee below for details on the topics. The slides page lists all the available presentations."
  },
  {
    "objectID": "meetings/25.1-meeting.html#venue",
    "href": "meetings/25.1-meeting.html#venue",
    "title": "First RTUG meeting",
    "section": " Venue",
    "text": "Venue\nAula Rossa of the Department of Economics and Management, via Inama 5, Trento."
  },
  {
    "objectID": "meetings/25.1-meeting.html#details-on-topics",
    "href": "meetings/25.1-meeting.html#details-on-topics",
    "title": "First RTUG meeting",
    "section": " Details on Topics",
    "text": "Details on Topics\n\nWelcome\n\nAuthor: P. Bosetti, University of Trento\nStyle: Presentation\n\n\n\nThe R Package rmf in Teaching\n\nAuthors: R. Micciolo and G. Espa, University or Trento\nStyle: Presentation\n\nWe introduce the rmf package, which contains a series of functions developed primarily for use in educational settings, particularly in basic university statistics courses.\n\n\nThe adas.utils Package: Design of Experiments, the Tidy Way\n\nAuthor: P. Bosetti, University or Trento\nStyle: Presentation\n\nWe introduce the adas.utils package, which provides a set of tools for designing factorial designs and analyzing results, in line with the Tidyverse package approach.\n\n\nBioinformatics and R: Visualizing Genomic Data\n\nAuthor: Y. Ciani, University or Trento\nStyle: Presentation\n\nAn overview of the use of R in bioinformatics, particularly its use for visualizing genomic data.\n\n\nSpatial Sampling in R\n\nAuthor: M. M. Dickson, University of Padua\nStyle: Presentation\n\nWe introduce the BalancedSampling package, which allows the selection of balanced and spatially balanced samples, widely used in the environmental/forestry field, with recent diffusion also in the economic-social field."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contacts and updates",
    "section": "",
    "text": "Email\nIf you are interested in the RTUG activities, please contact the RTUG group (rtug.group at unitn dot it).\nIf you want to inquire about this web site, please contact Paolo Bosetti (paolo.bosetti at unitn dot it).\n\n\n RSS feeds\nYou can stay updated using the following feeds:\n\n\n List of meetings\n List of posts\n\n\n\n\n More info\nMore info on the group and on this website on the about page"
  },
  {
    "objectID": "slides/dickson-25.1.html",
    "href": "slides/dickson-25.1.html",
    "title": "Spatial Sampling in R",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "slides/ciani-25.1.html",
    "href": "slides/ciani-25.1.html",
    "title": "Bioinformatics and R: Visualizing Genomic Data",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "RTUG",
    "section": "",
    "text": "Affiliation\nThe group has been founded by faculty members of the University of Trento and the group Internet domain name rtug.unitn.it is provided by the same University.\n\n\nSponsor\n\nR-Trento Users Group is kindly sponsored by the R consortium.\nWe follow the R Consortium and the R Community Code of Conduct.\n\n\nLogo\nThe R-Trento Users Group logo uses the green and blue hues from our Province, it has the customary hexagonal shape made popular by tidyverse, and uses the official R language logo in the word “TRENTO”.\nNote that the official R logo is used under Creative Commons Attribution-ShareAlike 4.0 International license (CC-BY-SA 4.0)\n\n\nLicense\nThe content provided by this site are covered by Creative Commons Attribution-ShareAlike 4.0 International license\nThe CC-BY-SA 4.0 license allows you to share and adapt the logo for any purpose, including commercial use, provided that you give appropriate credit, provide a link to the license, and indicate if any changes were made.\n\n\nWebsite\nThis site is built on tools from the R network, using Quarto in the RStudio IDE."
  },
  {
    "objectID": "bibliography.html",
    "href": "bibliography.html",
    "title": "Bibliography",
    "section": "",
    "text": "Members of RTUG have contributed to the following topics:\n\n CRAN Packages\n\nADAS Utils—Design of Experiments\nnoisyCE2—Cross-Entropy Optimisation of Noisy Functions\nRMAWGEN—Multi-Site Auto-Regressive Weather GENerator\ngeotopbricks—An R Plug-in for the Distributed Hydrological Model GEOtop\n\n\n\n\n\n\n\n\n\n Books\n\nAgresti A., C. Franklin, B. Klingenberg (2025) Statistica — l’arte e la scienza d’imparare dai dati (quinta edizione), Pearson Italia, Milano (a cura di G. Espa, R. Micciolo, D. Giuliani, M.M. Dickson). ISBN: 9788891931894.\nBosetti, P. (2022) Fondamenti di statistica — Per le misure e l’analisi dati in ambito industriale. Con esempi in GNU-R. Libreriauniversitaria.it. ISBN: 978-8833595188.\nMicciolo R., L. Canal, G. Espa (2021) Probabilità e modelli – Teoria e pratica con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 978-88-916-4935-5.\nEspa G., R. Micciolo (2014) Problemi ed Esperimenti di Statistica con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838786105.\nBee M, F. Santi (2013) Finanza quantitativa con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838787041.\nR. Micciolo, G. Espa, L. Canal (2013) Ricerca con R – Metodi di inferenza statistica, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN: 8838787003.\nEspa G., R. Micciolo (2012) Analisi esplorativa dei dati con R, Apogeo Education, Maggioli Editore, Santarcangelo di Romagna (RN). ISBN 8838786853.\n\n\n\n Papers\n\nSanti F., M.M. Dickson, G. Espa, D. Giuliani (2022) plot3logit: Ternary Plots for Interpreting Trinomial Regression Models, Journal of Statistical Software, Code Snippets, 103 (1), 1–27. DOI: 10.18637/jss.v103.c01.\nGiuliani D., M.M. Dickson, G. Espa (2015) Teaching statistics in the context of social foresight. An applied approach based on the use of an open-source software, On the Horizon, 23, 2, 140–148. DOI: 10.1108/OTH-02-2015-0010.\nCanal L., Micciolo R. (2008) The proportional means regression model for the analysis of recurrent event data. BioMedical Statistics and Clinical Epidemiology, 2:2, 157-169 (pdf here).\nCanal L., Micciolo R. (2014) The chi-square controversy: what if Pearson had R?. Journal of Statistical Computation and Simulation, 84:5, 1015-1021. DOI: 10.1080/00949655.2012.737793\nDecarli A., La Vecchia C., Malvezzi M., Micciolo R. (2014) An R package for fitting age, period and cohort models. Epidemiology Biostatistics and Public Health, 11:4, e9977-1 – e9977-12. DOI: 10.2427/9977 (pdf here).\nFedrizzi G., Canal L., Micciolo R. (2022). UEFA EURO 2020: An exciting match between football and probability. Teaching Statistics, 44:3, 119-125. DOI: 10.1111/test.12315 (pdf here)."
  },
  {
    "objectID": "slides/rtug-25.1.html#rtug-what-is-it",
    "href": "slides/rtug-25.1.html#rtug-what-is-it",
    "title": "rtug::25.1",
    "section": " RTUG: what is it?",
    "text": "RTUG: what is it?\n\n\n\nWe are an informal group of R users and developers based in Trento or connected with this territory, in any way\nActivities are funded by the R-Consortium\nMeetings are published on Meetup\nWe aim at two meetings per year (minimum)\nMeetings are open to your contributions too!\nOur website, rtug.unitn.it, is also open to contributed posts\n\n\n\n\n\nbit.ly/RTUG"
  },
  {
    "objectID": "slides/rtug-25.1.html#seminars",
    "href": "slides/rtug-25.1.html#seminars",
    "title": "rtug::25.1",
    "section": " Seminars",
    "text": "Seminars\n\nWelcome and Introduction to the R-Trento Users Group (P. Bosetti)\nThe R Package rmf in Teaching (R. Micciolo and G. Espa) \nThe adas.utils Package: Design of Experiments, the Tidy Way (P. Bosetti) \nBioinformatics and R: Visualizing Genomic Data (Y. Ciani) \nSpatial Sampling in R (M. M. Dickson)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#design-of-experiments-and-factorial-plans",
    "href": "slides/bosetti-25.1/index.html#design-of-experiments-and-factorial-plans",
    "title": "The adas.utils package",
    "section": "Design of Experiments and factorial plans",
    "text": "Design of Experiments and factorial plans\n\n\n\nDesign of Experiments (DoE) is a collection of statistical techniques to plan and analyze industrial experiments\nPredictors are typically many (10 or more), and can be continuous or categorical\nOften a first-order model is enough\nFitting a response surface on a multidimensional grid can be costly\n\nDoE aims at getting the most information from a minimum of experiments\n\n\n\n\n\n\n\n\n\n See the famous “Design and Analysis of Experiments”, by Douglas C. Montgomery, 10th edition, Wiley, 2020."
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#doe-in-brief",
    "href": "slides/bosetti-25.1/index.html#doe-in-brief",
    "title": "The adas.utils package",
    "section": "DoE in brief",
    "text": "DoE in brief\n\n\n\nPlan for a grid of treatments (factorial plan) in the \\(n\\)-hyperspace, where \\(n\\) is the number of predictors, or process parameters\nThe FP can be optimized, sacrificing completeness for efficiency (Fractional Factorial Plans)\nThe FP must be randomized, to reduce bias due to systematic errors\nThe FP can be non-replicated, to further reduce costs (Daniel’s method)\nThe FP can be augmented, to add new treatments to an existing plan (Augmented Factorial Plans)\nWe use coded units (i.e. normalized to \\([-1,1]\\))\n\n\n\n\n\n2 factors CCD\n\n\n\n\n\n3 factors CCD"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r",
    "href": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r",
    "title": "The adas.utils package",
    "section": "Simple example in vanilla R",
    "text": "Simple example in vanilla R\nCreate a non-replicated full factorial plan with three factors, two levels each (\\(2^3\\)):\n\n\n# Make the grid\nfp &lt;- expand.grid(\n  A=c(-1,1), \n  B=c(-1,1), \n  C=c(-1,1), \n  Y=NA\n)\n\n# Add orders\nfp$StdOrder &lt;- 1:nrow(fp)\nfp$RunOrder &lt;- sample(nrow(fp))\nfp\n\n\n   A  B  C  Y StdOrder RunOrder\n1 -1 -1 -1 NA        1        3\n2  1 -1 -1 NA        2        2\n3 -1  1 -1 NA        3        8\n4  1  1 -1 NA        4        4\n5 -1 -1  1 NA        5        5\n6  1 -1  1 NA        6        7\n7 -1  1  1 NA        7        1\n8  1  1  1 NA        8        6\n\n\nThen save it (typ. as CSV), perform the experiments, fill the Y yield column, and load it back for the analysis\n\n\n In a replicated \\(k\\cdot2^n\\) FP, the replica index is formally just another factor with \\(k\\) levels"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-1",
    "href": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-1",
    "title": "The adas.utils package",
    "section": "Simple example in vanilla R",
    "text": "Simple example in vanilla R\nFor a fractional factorial plan, we reject one half of the FP according to a defining relationship: \\(I=ABC\\), which can be transformed as \\(C=AB\\) \nWe remove rows where the sign of \\(C\\) is the product of \\(A\\) and \\(B\\):\n\n\n# Extract the fraction where C=AB\nffp &lt;- fp[fp$C==fp$A*fp$B, ]\n\n# Add orders\nfp$StdOrder &lt;- 1:nrow(fp)\nffp$RunOrder &lt;- sample(nrow(ffp))\nffp\n\n\n   A  B  C  Y StdOrder RunOrder\n2  1 -1 -1 NA        2        2\n3 -1  1 -1 NA        3        3\n5 -1 -1  1 NA        5        1\n8  1  1  1 NA        8        4\n\n\nBut mind you! for this to work, columns A, B, and C must NOT be factors! (in the R sense)\n\n\n\n Remark on defining relationships\n\n\nIt holds the signs algebra: \\(X\\cdot X=I,~I\\cdot X = X\\), thus \\(CI = ABCC~\\rightarrow~C=AB\\)\n\n\n\n\n\n When factors become numerous, and when you need to fraction two or three or more times, the above operations become cumbersome and error prone"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-2",
    "href": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-2",
    "title": "The adas.utils package",
    "section": "Simple example in vanilla R",
    "text": "Simple example in vanilla R\nAnalyzing the FP is mostly a matter of:\n\ndefining a linear model, Y~A*B*C\nusing lm() to fit the model\nusing residuals() to check the residuals for normality and patterns\nusing anova() to analyze the model\nsimplify the model if necessary\n\nBut if the FP is non-replicated, you can’t fit a model unless you remove some terms from the general linear model Y~A*B*C. To do so, Daniel’s method suggests to make a Q-Q plot of the effects: not straightforward"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-3",
    "href": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-3",
    "title": "The adas.utils package",
    "section": "Simple example in vanilla R",
    "text": "Simple example in vanilla R\nAs an example for a \\(2^4\\) FP, the Daniel’s Q-Q plot of the effects can be obtained by:\n\n\n# build a full linear model:\nfp.lm &lt;- lm(Y ~ A*B*C*D, data=fp)\n\n# prepare plot data:\nlen     &lt;- length(fp.lm$effects)\neffects &lt;- fp.lm$effects[2:len]\n\n# Q-Q plot:\nqq      &lt;- qqnorm(effects)\nqqline(effects)\n\n# add names:\ntext(qq$x, qq$y, \n     labels=names(effects))\n\n\n\n\n\n\n\n\n\n\n\n Problems: not immediate; the plot is not really clean and it often needs tuning (scales and labels size)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-4",
    "href": "slides/bosetti-25.1/index.html#simple-example-in-vanilla-r-4",
    "title": "The adas.utils package",
    "section": "Simple example in vanilla R",
    "text": "Simple example in vanilla R\n Problems:\n\n\n\ndifficult to manage scaled units vs. non scaled units\nfactor names aren’t mnemonic (which parameter is represented by F?)\nfractioning an FP is not trivial\nDaniel’s method is tricky and repetitive\naugmenting a plan is not trivial when the number of factors is 4 or more\neverything is not very tidy (in the sense of tidyverse)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#enter-adas.utils-package",
    "href": "slides/bosetti-25.1/index.html#enter-adas.utils-package",
    "title": "The adas.utils package",
    "section": "Enter adas.utils package",
    "text": "Enter adas.utils package\nThe package is available on CRAN:\n\n\ninstall.packages(\"adas.utils\")\nlibrary(adas.utils)\n\n\n\nDon’t forget to look at the vignette:\n\n\nvignette(\"adas.utils\")"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#plain-fps",
    "href": "slides/bosetti-25.1/index.html#plain-fps",
    "title": "The adas.utils package",
    "section": "Plain FPs",
    "text": "Plain FPs\nBase \\(2\\cdot 2^2\\) FP:\n\n\nlibrary(adas.utils)\n\n# Two factors, two replicas\nfp_design_matrix(2, rep=2)\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B \n Factors:  A B \n Levels:  -1 1 \n Fraction:  NA \n Type:  plain \n \n# A tibble: 8 × 7\n  StdOrder RunOrder .treat  .rep     A     B Y    \n     &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n1        1        6 (1)        1    -1    -1 NA   \n2        2        8 a          1     1    -1 NA   \n3        3        4 b          1    -1     1 NA   \n4        4        7 ab         1     1     1 NA   \n5        5        2 (1)        2    -1    -1 NA   \n6        6        3 a          2     1    -1 NA   \n7        7        1 b          2    -1     1 NA   \n8        8        5 ab         2     1     1 NA   \n\n\n\n\n\n\n\n\nNote\n\n\nNote the Yates’ treatment names in .treat column\n\n\n\n\n\n The object returned, class factorial.plan, is a tibble with added attributes that keep track of the design"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#plain-fps-with-named-factors",
    "href": "slides/bosetti-25.1/index.html#plain-fps-with-named-factors",
    "title": "The adas.utils package",
    "section": "Plain FPs, with named factors",
    "text": "Plain FPs, with named factors\nWe can tie factors with corresponding parameter names:\n\n\n# Two factors, two replicas, \n# with names\nfp_design_matrix(2, rep=2) %&gt;%\n  fp_add_names(\n    A=\"Temperature\",\n    B=\"Pressure\"\n  )\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B \n Factors:  A B \n Levels:  -1 1 \n Fraction:  NA \n Type:  plain \n Factor names:\n    A: Temperature\n    B: Pressure\n \n# A tibble: 8 × 7\n  StdOrder RunOrder .treat  .rep     A     B Y    \n     &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n1        1        3 (1)        1    -1    -1 NA   \n2        2        7 a          1     1    -1 NA   \n3        3        4 b          1    -1     1 NA   \n4        4        5 ab         1     1     1 NA   \n5        5        8 (1)        2    -1    -1 NA   \n6        6        2 a          2     1    -1 NA   \n7        7        6 b          2    -1     1 NA   \n8        8        1 ab         2     1     1 NA   \n\n\n\n\n Note that it’s been designed to support the magrittr pipe operator %&gt;% (or the native R one |&gt;)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#plain-fps-with-named-factors-and-actual-scales",
    "href": "slides/bosetti-25.1/index.html#plain-fps-with-named-factors-and-actual-scales",
    "title": "The adas.utils package",
    "section": "Plain FPs, with named factors and actual scales",
    "text": "Plain FPs, with named factors and actual scales\nActual scales can be added for reference:\n\n\n# Two factors, two replicas, \n# with names and scales\nfp_design_matrix(2, rep=2) %&gt;% \n  fp_add_names(\n    A=\"Temperature\", \n    B=\"Pressure\"\n  ) %&gt;% \n  fp_add_scale(\n    A=c(20, 25), \n    B=c(75, 125), \n    suffix=\".scaled\"\n  ) %&gt;% \n  # Just to keep output compact 😎 \n  select(-c(StdOrder, RunOrder))\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B \n Factors:  A B \n Levels:  -1 1 \n Fraction:  NA \n Type:  plain \n Scales suffix: .scaled\n Scaled factors:\n    A.scaled: [20, 25]\n    B.scaled: [75, 125]\n Factor names:\n    A: Temperature\n    B: Pressure\n \n# A tibble: 8 × 7\n  .treat  .rep     A     B A.scaled B.scaled Y    \n  &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;\n1 (1)        1    -1    -1       20       75 NA   \n2 a          1     1    -1       25       75 NA   \n3 b          1    -1     1       20      125 NA   \n4 ab         1     1     1       25      125 NA   \n5 (1)        2    -1    -1       20       75 NA   \n6 a          2     1    -1       25       75 NA   \n7 b          2    -1     1       20      125 NA   \n8 ab         2     1     1       25      125 NA   \n\n\n\n\n Note that it’s been designed to support the magrittr pipe operator %&gt;% (or the native R one |&gt;)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#augmented-fps",
    "href": "slides/bosetti-25.1/index.html#augmented-fps",
    "title": "The adas.utils package",
    "section": "Augmented FPs",
    "text": "Augmented FPs\nWe can augment a \\(2^n\\) FP with a central treatment:\n\n\n# Three factors, scaled\nfp_design_matrix(3) %&gt;%\n  fp_add_scale(B=c(10, 20)) %&gt;% \n  \n  # Augment with a central treatment\n  fp_augment_center(rep=4) %&gt;% \n  \n  # Just to keep output compact 😎 \n  slice_tail(n=6)\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B * C \n Factors:  A B C \n Levels:  -1 1 \n Fraction:  NA \n Type:  centered \n Scales suffix: _s\n Scaled factors:\n    B_s: [10, 20]\n \n# A tibble: 6 × 9\n  StdOrder RunOrder .treat  .rep     A     B     C   B_s Y    \n     &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n1        7        3 bc         1    -1     1     1    20 NA   \n2        8        2 abc        1     1     1     1    20 NA   \n3        9       12 center     1     0     0     0    15 NA   \n4       10       10 center     2     0     0     0    15 NA   \n5       11        9 center     3     0     0     0    15 NA   \n6       12       11 center     4     0     0     0    15 NA"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#augmented-fps-1",
    "href": "slides/bosetti-25.1/index.html#augmented-fps-1",
    "title": "The adas.utils package",
    "section": "Augmented FPs",
    "text": "Augmented FPs\nAnd then further augment the FP with axial treatments to get a rotatable Composite Centered Design (CCD):\n\n\nfp_design_matrix(2) %&gt;%\n  fp_add_scale(\n    A=c(7,18), \n    B=c(10, 20)) %&gt;%\n  fp_augment_center(rep=1) %&gt;%\n  # Also augment with axial treatments\n  fp_augment_axial(rep=1) %&gt;% \n  # Just to keep output compact 😎 \n  select(-RunOrder) %&gt;% \n  as_tibble() # don't print header\n\n\n# A tibble: 9 × 8\n  StdOrder .treat  .rep     A     B   A_s   B_s Y    \n     &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n1        1 (1)        1 -1    -1     7    10    NA   \n2        2 a          1  1    -1    18    10    NA   \n3        3 b          1 -1     1     7    20    NA   \n4        4 ab         1  1     1    18    20    NA   \n5        5 center     1  0     0    12.5  15    NA   \n6        6 axial      1  0    -1.41 12.5   7.93 NA   \n7        7 axial      1 -1.41  0     4.72 15    NA   \n8        8 axial      1  1.41  0    20.3  15    NA   \n9        9 axial      1  0     1.41 12.5  22.1  NA   \n\n\n\n\n\n\n\n\nNote\n\n\nAutomatically scaling CCDs helps a lot in correctly defining process settings for each treatment\n\n\n\n\n\n Converted to a tibble to reduce the printout length"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#augmented-fps-2",
    "href": "slides/bosetti-25.1/index.html#augmented-fps-2",
    "title": "The adas.utils package",
    "section": "Augmented FPs",
    "text": "Augmented FPs\nAnd then further augment the FP with axial treatments to get a rotatable Centered Composite Design (CCD):\n\n\nfp_design_matrix(2) %&gt;%\n  fp_add_scale(\n    A=c(7,18), \n    B=c(10, 20)) %&gt;%\n  fp_augment_center(rep=1) %&gt;%\n  fp_augment_axial(rep=1) %&gt;% \n  # Make a plot\n  ggplot(aes(x=A, y=B)) + \n  geom_circle(\n    aes(x0=0, y0=0, r=sqrt(2)), \n    lty=2, color=gray(0.5)) +\n  geom_label(aes(label=.treat)) +\n  coord_fixed(xlim=c(-1.5,1.5)*6/4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nOf course it works on higher dimensions as well"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#fractional-factorial-plans",
    "href": "slides/bosetti-25.1/index.html#fractional-factorial-plans",
    "title": "The adas.utils package",
    "section": "Fractional Factorial Plans",
    "text": "Fractional Factorial Plans\nWe can fraction a \\(2^n\\) FP by adding subsequent defining relationships:\n\n\nfp_design_matrix(5) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_fraction(~B*C*D*E) %&gt;%\n  select(-c(StdOrder,RunOrder,.rep))\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B * C * D * E \n Factors:  A B C D E \n Levels:  -1 1 \n Fraction:  I=ABCD I=BCDE \n Type:  fractional \n \n# A tibble: 8 × 9\n  .treat     A     B     C     D     E Y      ABCD  BCDE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 (1)       -1    -1    -1    -1    -1 NA        1     1\n2 bc        -1     1     1    -1    -1 NA        1     1\n3 bd        -1     1    -1     1    -1 NA        1     1\n4 cd        -1    -1     1     1    -1 NA        1     1\n5 abe        1     1    -1    -1     1 NA        1     1\n6 ace        1    -1     1    -1     1 NA        1     1\n7 ade        1    -1    -1     1     1 NA        1     1\n8 abcde      1     1     1     1     1 NA        1     1"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#save-design-matrix",
    "href": "slides/bosetti-25.1/index.html#save-design-matrix",
    "title": "The adas.utils package",
    "section": "Save design matrix",
    "text": "Save design matrix\nYou can save the design matrix as CSV file (for collecting experimental data), then load it back into the original FP object (thus preserving attributes):\n\n\nfp &lt;- fp_design_matrix(4) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_write_csv(\"fp.csv\")\n\nfp &lt;- fp %&gt;% \n  fp_read_csv(\"fp.csv\")\n\nfp %&gt;% select(-RunOrder)\n\n\n Factorial Plan Design Matrix\n Defining Relationship:  ~ A * B * C * D \n Factors:  A B C D \n Levels:  -1 1 \n Fraction:  I=ABCD \n Type:  fractional \n \n# A tibble: 8 × 9\n  StdOrder .treat  .rep     A     B     C     D Y      ABCD\n     &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;\n1        1 (1)        1    -1    -1    -1    -1 NA        1\n2        4 ab         1     1     1    -1    -1 NA        1\n3        6 ac         1     1    -1     1    -1 NA        1\n4        7 bc         1    -1     1     1    -1 NA        1\n5       10 ad         1     1    -1    -1     1 NA        1\n6       11 bd         1    -1     1    -1     1 NA        1\n7       13 cd         1    -1    -1     1     1 NA        1\n8       16 abcd       1     1     1     1     1 NA        1\n\n\n\n\n\n\n\n\nNote\n\n\nThe saved CSV file has a commented header with FFP details (e.g. defining relationships, factors names, scales, etc.)"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#alias-structures",
    "href": "slides/bosetti-25.1/index.html#alias-structures",
    "title": "The adas.utils package",
    "section": "Alias structures",
    "text": "Alias structures\nFractioning a FP creates alias structures: the adas.utils package can help you with that too:\n\n\nfp_alias_matrix(~A*B*C, ~B*C*D)\n\n\nDefining relationships:\n I=ABC I=BCD I=AD \n\n     A B AB C AC BC ABC D AD BD ABD CD ACD BCD ABCD\nA    0 0  0 0  0  1   0 3  0  0   0  0   0   0    2\nB    0 0  0 0  1  0   0 0  0  0   3  2   0   0    0\nAB   0 0  0 1  0  0   0 0  0  3   0  0   2   0    0\nC    0 0  1 0  0  0   0 0  0  2   0  0   3   0    0\nAC   0 1  0 0  0  0   0 0  0  0   2  3   0   0    0\nBC   1 0  0 0  0  0   0 2  0  0   0  0   0   0    3\nABC  0 0  0 0  0  0   0 0  2  0   0  0   0   3    0\nD    3 0  0 0  0  2   0 0  0  0   0  0   0   0    1\nAD   0 0  0 0  0  0   2 0  0  0   0  0   0   1    0\nBD   0 0  3 2  0  0   0 0  0  0   0  0   1   0    0\nABD  0 3  0 0  2  0   0 0  0  0   0  1   0   0    0\nCD   0 2  0 0  3  0   0 0  0  0   1  0   0   0    0\nACD  0 0  2 3  0  0   0 0  0  1   0  0   0   0    0\nBCD  0 0  0 0  0  0   3 0  1  0   0  0   0   0    0\nABCD 2 0  0 0  0  3   0 1  0  0   0  0   0   0    0"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#alias-structures-1",
    "href": "slides/bosetti-25.1/index.html#alias-structures-1",
    "title": "The adas.utils package",
    "section": "Alias structures",
    "text": "Alias structures\nThe alias matrix can be plotted directly, via ggplot2:\n\n\nfp_alias_matrix(~A*B*C, ~B*C*D) %&gt;% \n  plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe third generator is the dependent one, i.e. the one that has all terms not in common in the first two generators"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#daniels-method",
    "href": "slides/bosetti-25.1/index.html#daniels-method",
    "title": "The adas.utils package",
    "section": "Daniel’s method",
    "text": "Daniel’s method\nThe adas.utils package can also help you with Daniel’s method: the daniel_plot_hn() function takes a linear model object and returns a half-normal plot of the effects:\n\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  daniel_plot_hn(nlab=6,repel=TRUE) +\n  labs(title=\"Rev. model: Y~A*C+A*D\")"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#pareto-chart-of-the-effects",
    "href": "slides/bosetti-25.1/index.html#pareto-chart-of-the-effects",
    "title": "The adas.utils package",
    "section": "Pareto chart of the effects",
    "text": "Pareto chart of the effects\nIt’s easy to build a Pareto chart of the effects in a linear model:\n\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  pareto_chart() +\n  theme(\n    legend.position = \"bottom\",\n    axis.text.x = \n      element_text(angle=45,hjust=1))"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#tukey-plots",
    "href": "slides/bosetti-25.1/index.html#tukey-plots",
    "title": "The adas.utils package",
    "section": "Tukey plots",
    "text": "Tukey plots\nTukey’s test TukeyHSD() is not compatible with ggplot2, and its output pretty limited (and not very appealing). The adas.utils package provides a ggTukey() function that can be used to plot the results of Tukey’s test, also with multiple groups:\n\n\nbattery %&gt;%\n  ggTukey(Response~Material, \n          splt=~Temperature, \n          conf.level=0.99)\n\n\n\n\n\n\n\n\n\n\n\n ggTukey() is a generic with two methods: ggTukey.data.frame() and ggTukey.TukeyHSD()"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#alternatives",
    "href": "slides/bosetti-25.1/index.html#alternatives",
    "title": "The adas.utils package",
    "section": "Alternatives?",
    "text": "Alternatives?\nOnly pre-tidyverse packages as:\n\nDoE.base\nFrF2"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#future-developments",
    "href": "slides/bosetti-25.1/index.html#future-developments",
    "title": "The adas.utils package",
    "section": "Future developments",
    "text": "Future developments\n\nadas.utils is currently v1.2.0 on CRAN\n\n install.packages(\"adas.utils\")\n\nDevelopment version on GitHub v1.2.1\n\n devtools::install_github(\"pbosetti/adas.utils\")\n\nThe package is open to contributions \nCurrently working on:\n\na tool that suggests minimum aberration designs for FFPs \\(2^{n-p}\\) where \\(p\\geq 2\\)\nblocking structures\n\n\n\n\n Development on: github.com/pbosetti/adas.utils"
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#one-last-thing",
    "href": "slides/bosetti-25.1/index.html#one-last-thing",
    "title": "The adas.utils package",
    "section": "One last thing…",
    "text": "One last thing…\nPresentations made in Quarto can be interactive too…\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "slides/bosetti-25.1/index.html#one-last-thing-1",
    "href": "slides/bosetti-25.1/index.html#one-last-thing-1",
    "title": "The adas.utils package",
    "section": "One last thing…",
    "text": "One last thing…\nPresentations made in Quarto can be interactive too…\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "slides/micciolo-espa-25.1.html",
    "href": "slides/micciolo-espa-25.1.html",
    "title": "The R Package rmf in Teaching",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Members posts",
    "section": "",
    "text": "This is a selection of the most interesting posts contributed by our members.\n\n\n\n\n\n\nHow to contribute\n\n\n\nIf you want to contribute, head on to the GitHub repo, fork it, add a new post in the posts folder, tag it with the post category and make a pull request.\n\n\n\n Posts\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTukey vs. Student\n\n5 min\n\n\nR\n\ntidyverse\n\ninference\n\nTukey\n\n\n\nTo compare two samples, or groups, we can use a T-test. But if we want to compare more than two groups, we need to use Tukey’s test. In this post we investigate the reason…\n\n\n\nPaolo Bosetti\n\n\nApr 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nTukey’s test plot in adas.utils\n\n3 min\n\n\nR\n\npackages\n\n\n\nThe new version 1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test.\n\n\n\nPaolo Bosetti\n\n\nMar 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the adas.utils package\n\n7 min\n\n\npackages\n\npost\n\nCRAN\n\ndesign of experiments\n\n\n\nThe package adas.utils, contributed by one of RTUG members, aims at helping in the design and analysis of factorial experiments.\n\n\n\nPaolo Bosetti\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogarithmic scales in GGPlot2\n\n5 min\n\n\npost\n\nR\n\ntidyverse\n\nGGPlot2\n\nsignal analysis\n\n\n\nWith the excuse of doing signal analysis in R, this post discusses on how to deal with logarithmic scales and tick-marks in GGPlot2, and how to generate log-spaced grids to…\n\n\n\nPaolo Bosetti\n\n\nFeb 9, 2025\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nNote\n\n\n\n Unless otherwise specified, all content is licensed as BY-NC-SA 4.0."
  },
  {
    "objectID": "meetings.html",
    "href": "meetings.html",
    "title": "Meetings",
    "section": "",
    "text": "Meetings organized by RTUG\n\n\n\nMeetings and events are organized and shared via Meetup.com.\nParticipation is free and open to everyone, provided that you sign up for the meeting on Meetup.com.\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\nDescription\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nFirst RTUG meeting\n\n\nPaolo Bosetti\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R-Trento Users Group (RTUG)",
    "section": "",
    "text": "The R-Trento Users Group is a shared space for academics, scholars, students, and professionals living and working in Trentino and surrounding areas that are passionate about the R language and its suite of tools.\nThe suggested pronunciation for RTUG is “Ar-TOO(g)”, akin to the Italian “Artù”.\n\n Mission\nRTUG mission is to spread the use or R language and tools within academia, industry and public administration.\n\n\n\n\n\n How it works\nRTUG is a community-driven group. We organize meetings, workshops, and seminars, we share news, and we publish posts and tutorials. We are open to collaborations and partnerships with other groups and organizations.\nMeetings are the core of our activities: we plan to have two to three meetings per year, with a mix of invited speakers, tutorials, and member presentations. Meetings can be a great opportunity for networking, learning, sharing experiences, and possibly finding new collaborations or solution providers.\nTo collaborate with RTUG, you can:\n\nBecome a member: contact the group (rtug.group at unitn dot it?subject=%5BRTUG%5D%20Becoming%20a%20member) and ask for instructions. Membership if free and open to anyone interested. Please note that, to simplify the management of members mailing list, we are currently accepting one member per institution/department/workgroup.\nGet to know us: join our meetings\nVolunteer and advertise your R skills: contribute a post\n\n\n\n Next meeting\n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\nDescription\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nFirst RTUG meeting\n\n\nPaolo Bosetti\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n News\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nTukey vs. Student\n\n\n\nR\n\ntidyverse\n\ninference\n\nTukey\n\n\n\nTo compare two samples, or groups, we can use a T-test. But if we want to compare more than two groups, we need to use Tukey’s test. In this post we investigate the reason why a Tukey’s test is more appropriate and robust than a set of pairwise T-tests for all possible combinations of groups. This is also an excuse to illustrate the power of purrr and dplyr packages, specifically for the use of map/reduce, join_left, and pivot_longer/pivot_wider functions.\n\n\n\n\n\nApr 10, 2025\n\n\nPaolo Bosetti\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nR-Consortium supporting RTUG\n\n\n\nRTUG\n\nmilestone\n\nannouncement\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nTukey’s test plot in adas.utils\n\n\n\nR\n\npackages\n\n\n\nThe new version 1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test.\n\n\n\n\n\nMar 27, 2025\n\n\nPaolo Bosetti\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nMoving to a new domain\n\n\n\nRTUG\n\nmilestone\n\n\n\nRTUG website has a new domain and a new contact email.\n\n\n\n\n\nFeb 26, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the adas.utils package\n\n\n\npackages\n\npost\n\nCRAN\n\ndesign of experiments\n\n\n\nThe package adas.utils, contributed by one of RTUG members, aims at helping in the design and analysis of factorial experiments.\n\n\n\n\n\nFeb 10, 2025\n\n\nPaolo Bosetti\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\nLogarithmic scales in GGPlot2\n\n\n\npost\n\nR\n\ntidyverse\n\nGGPlot2\n\nsignal analysis\n\n\n\nWith the excuse of doing signal analysis in R, this post discusses on how to deal with logarithmic scales and tick-marks in GGPlot2, and how to generate log-spaced grids to have an equally dense set of points in the resulting plot.\n\n\n\n\n\nFeb 9, 2025\n\n\nPaolo Bosetti\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\nNew Logo\n\n\n\nRTUG\n\nwebsite\n\nannouncement\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\nOpening!\n\n\n\nRTUG\n\nmilestone\n\nannouncement\n\n\n\n\n\n\n\n\n\nFeb 5, 2025\n\n\nPaolo Bosetti\n\n1 min\n\n\n\n\nNo matching items\n\n\n\n On Bluesky\n\n\n\n\n\n\nLast post:\n\n\n\n\nLoading last post"
  },
  {
    "objectID": "posts/002-logo/index.html",
    "href": "posts/002-logo/index.html",
    "title": "New Logo",
    "section": "",
    "text": "We have a new group logo\n\n\n\n\n\nRTUG logo\n\n\nThe new RTUG logo is a hexagon, on the style of Tidyverse packages, it takes the colors of Trentino Province lettering, and of course it incorporates the GNU-R language logo."
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html",
    "title": "Tukey vs. Student",
    "section": "",
    "text": "Packages that we need\n\n\n\nIn this example, we are using the packages tidyverse and adas.utils version 1.1.4 (see https://github.com/pbosetti/adas.utils)\n\nlibrary(tidyverse)\nlibrary(adas.utils)"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#the-dataset",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#the-dataset",
    "title": "Tukey vs. Student",
    "section": "The dataset",
    "text": "The dataset\nLet us compare the result of a Tukey’s test with a repeated Student’s T-test on all combinations. We consider the cotton dataset, which is included in the adas.utils package from version 1.1.4. The dataset contains the tensile strength of mixed cotton-synthetic yarns with different cotton content:\n\ncotton %&gt;% \n  ggplot(aes(x=Cotton, y=Strength, group=Cotton)) +\n  geom_boxplot()"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#inference-on-strength",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#inference-on-strength",
    "title": "Tukey vs. Student",
    "section": "Inference on Strength",
    "text": "Inference on Strength\nNow we want to compare all the possibile combinations of treatmentswith a set of pairwise T-tests.\nFirst, we create the list of pairwise combinations, sorting each pair in descending order, as it is done by the TukeyHSD function:\n\nlvl &lt;- levels(cotton$Cotton) %&gt;% \n  combn(2, FUN=sort, decreasing=T) %&gt;% \n  as_tibble(.name_repair=\"minimal\") %&gt;% \n  as.list() %&gt;% glimpse()\n\nList of 10\n $ : chr [1:2] \"20\" \"15\"\n $ : chr [1:2] \"25\" \"15\"\n $ : chr [1:2] \"30\" \"15\"\n $ : chr [1:2] \"35\" \"15\"\n $ : chr [1:2] \"25\" \"20\"\n $ : chr [1:2] \"30\" \"20\"\n $ : chr [1:2] \"35\" \"20\"\n $ : chr [1:2] \"30\" \"25\"\n $ : chr [1:2] \"35\" \"25\"\n $ : chr [1:2] \"35\" \"30\"\n\n\nNow, for each pair we do a T-test on the corresponding cotton data-frame subset, and accumulate into a new tibble the values of interest. We get the df table that is analogous to the TukeyHSD output:\n\ndf &lt;- lvl %&gt;% reduce(\\(acc, pair) {\n  tt &lt;- cotton %&gt;% \n    filter(Cotton %in% pair) %&gt;% \n    t.test(Strength~Cotton, data=., var.equal=TRUE)\n  bind_rows(acc, list(\n    pair = paste0(pair[1], \"-\", pair[2]),\n    diff = -median(tt$conf.int),\n    lwr = -tt$conf.int[2],\n    upr = -tt$conf.int[1],\n    p.value = tt$p.value\n  ))\n}, .init=tibble()) \n\ndf %&gt;% knitr::kable()\n\n\n\n\npair\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\n5.6\n0.8740978\n10.3259022\n0.0257453\n\n\n25-15\n7.8\n3.7398608\n11.8601392\n0.0021967\n\n\n30-15\n11.8\n7.4246648\n16.1753352\n0.0002541\n\n\n35-15\n1.0\n-3.5423014\n5.5423014\n0.6253800\n\n\n25-20\n2.2\n-1.6724395\n6.0724395\n0.2265324\n\n\n30-20\n6.2\n1.9982605\n10.4017395\n0.0093233\n\n\n35-20\n-4.6\n-8.9753352\n-0.2246648\n0.0415629\n\n\n30-25\n4.0\n0.5641312\n7.4358688\n0.0277266\n\n\n35-25\n-6.8\n-10.4461127\n-3.1538873\n0.0026133\n\n\n35-30\n-10.8\n-14.7941163\n-6.8058837\n0.0002496\n\n\n\n\n\nTo be compared with Tukey’s values:\n\nttdf &lt;- TukeyHSD(aov(lm(Strength~Cotton, data=cotton)))$Cotton %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(var=\"pair\") %&gt;% \n  rename(p.value=`p adj`)\nttdf %&gt;% knitr::kable()\n\n\n\n\npair\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\n5.6\n0.2270417\n10.9729583\n0.0385024\n\n\n25-15\n7.8\n2.4270417\n13.1729583\n0.0025948\n\n\n30-15\n11.8\n6.4270417\n17.1729583\n0.0000190\n\n\n35-15\n1.0\n-4.3729583\n6.3729583\n0.9797709\n\n\n25-20\n2.2\n-3.1729583\n7.5729583\n0.7372438\n\n\n30-20\n6.2\n0.8270417\n11.5729583\n0.0188936\n\n\n35-20\n-4.6\n-9.9729583\n0.7729583\n0.1162970\n\n\n30-25\n4.0\n-1.3729583\n9.3729583\n0.2101089\n\n\n35-25\n-6.8\n-12.1729583\n-1.4270417\n0.0090646\n\n\n35-30\n-10.8\n-16.1729583\n-5.4270417\n0.0000624\n\n\n\n\n\nNow let’s join both tables and make a common plot:\n\ncompared &lt;- df %&gt;% \n  left_join(ttdf, by=join_by(pair), suffix=c(\".student\", \".tukey\")) %&gt;% \n  pivot_longer(-pair, names_to = c(\"stat\", \"test\"), names_pattern = \"(.*)\\\\.(student|tukey)$\") %&gt;% \n  pivot_wider(names_from = stat)\n\ncompared %&gt;% knitr::kable()\n\n\n\n\npair\ntest\ndiff\nlwr\nupr\np.value\n\n\n\n\n20-15\nstudent\n5.6\n0.8740978\n10.3259022\n0.0257453\n\n\n20-15\ntukey\n5.6\n0.2270417\n10.9729583\n0.0385024\n\n\n25-15\nstudent\n7.8\n3.7398608\n11.8601392\n0.0021967\n\n\n25-15\ntukey\n7.8\n2.4270417\n13.1729583\n0.0025948\n\n\n30-15\nstudent\n11.8\n7.4246648\n16.1753352\n0.0002541\n\n\n30-15\ntukey\n11.8\n6.4270417\n17.1729583\n0.0000190\n\n\n35-15\nstudent\n1.0\n-3.5423014\n5.5423014\n0.6253800\n\n\n35-15\ntukey\n1.0\n-4.3729583\n6.3729583\n0.9797709\n\n\n25-20\nstudent\n2.2\n-1.6724395\n6.0724395\n0.2265324\n\n\n25-20\ntukey\n2.2\n-3.1729583\n7.5729583\n0.7372438\n\n\n30-20\nstudent\n6.2\n1.9982605\n10.4017395\n0.0093233\n\n\n30-20\ntukey\n6.2\n0.8270417\n11.5729583\n0.0188936\n\n\n35-20\nstudent\n-4.6\n-8.9753352\n-0.2246648\n0.0415629\n\n\n35-20\ntukey\n-4.6\n-9.9729583\n0.7729583\n0.1162970\n\n\n30-25\nstudent\n4.0\n0.5641312\n7.4358688\n0.0277266\n\n\n30-25\ntukey\n4.0\n-1.3729583\n9.3729583\n0.2101089\n\n\n35-25\nstudent\n-6.8\n-10.4461127\n-3.1538873\n0.0026133\n\n\n35-25\ntukey\n-6.8\n-12.1729583\n-1.4270417\n0.0090646\n\n\n35-30\nstudent\n-10.8\n-14.7941163\n-6.8058837\n0.0002496\n\n\n35-30\ntukey\n-10.8\n-16.1729583\n-5.4270417\n0.0000624\n\n\n\n\n\n\ncompared %&gt;%\n  ggplot(aes(x=diff, y=pair, color=test)) + \n  geom_point() + \n  geom_errorbar(aes(xmin=lwr, xmax=upr), width=0.5, position=position_dodge()) + \n  geom_vline(xintercept=0, color=\"red\") +\n  labs(x=\"Difference\", y=\"Pair\", title=\"95% pairwise confidence level\")"
  },
  {
    "objectID": "posts/008-tukey-vs-student/tukey-vs-student.html#the-family-wise-error-rate",
    "href": "posts/008-tukey-vs-student/tukey-vs-student.html#the-family-wise-error-rate",
    "title": "Tukey vs. Student",
    "section": "The Family-Wise Error Rate",
    "text": "The Family-Wise Error Rate\n\n\n\n\n\n\nThe Family-Wise Error Rate\n\n\n\nAs expected, the Tukey’s test in the last plot shows larger confidence intervals, that is, it has reduced chances of a false positive (Type I Error). More specifically, Tukey’s test controls the family-wise error rate (FWER) — the probability of making any false positive in the full set of comparisons.\n\n\nLet’s see why. If we set a confidence level of 0.95, it means that the probability of not making a Type I error on a single T-test is 0.95.\nFor 3 independent tests, the probability of no Type I error at all (in any of the tests) is: \\[\n0.95^3 \\approx 0.857\n\\] So the chance of making at least one Type I error is: \\[\n1 - 0.95^3 \\approx 0.143 \\quad \\text{(14.3\\%)}\n\\] That’s almost triple the risk you thought you were accepting! Furthermore, this risk increases exponentially with the number of comparisons. Given \\(n\\) elements, the number of possible combinations of \\(k\\) elements is given by the binomial coefficient: \\[\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\] In R, the latter is provided by the choose(n, k) function:\n\nchoose(5, 2)\n\n[1] 10\n\n\nso, with increasing number of classes to be compared, this is what happens to the probability of committing at least one Type-I error:\n\n2:15 %&gt;% reduce(\\(acc, k) {\n    nt &lt;- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-0.95^nt)\n    )\n  }, .init=tibble()) %&gt;% \n  ggplot(aes(x=n, y=p)) +\n  geom_point() +\n  geom_line() +\n  ylim(0, 1) +\n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\")\n\n\n\n\n\n\n\n\nAnd what happens if we change the confidence level? Let’s see, by creating a parametric plot similar to the ast one, but with different confidence levels. First we factor the last reduce opration into a function, FWER, that takes the confidence level as an argument. The function returns a tibble with the number of classes and the corresponding probability of Type I error.\n\nFWER &lt;- function(levels, conf.int=0.95) {\n  reduce(levels, \\(acc, k) {\n    nt &lt;- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-conf.int^nt)\n    )\n  }, .init=tibble()) \n}\n\nThen we apply the FWER function to a set of confidence levels, and join the results into a single tibble via the usual reduce, and finally, we plot the results:\n\ncl &lt;- c(0.9, 0.95, 0.99, 0.995, 0.999) \nN &lt;- 2:15\ncl %&gt;% \n  reduce(\\(acc, ci) {\n    fwer &lt;- FWER(N, ci) %&gt;% rename(!!paste0(\"cl-\", ci):=p)\n    left_join(acc, fwer, by=join_by(n))\n  }, .init=tibble(n=N)) %&gt;% \n  pivot_longer(-n, names_to = c(NA, \"cl\"), names_pattern=\"(cl-)(.*)\") %&gt;% \n  ggplot(aes(x=n, y=value, color=cl)) + \n  geom_point() + \n  geom_line() + \n  ylim(0, 1) + \n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\", \n    color=\"Conf. level\")\n\n\n\n\n\n\n\n\n\nThat’s all, folks!"
  },
  {
    "objectID": "posts/006-tukey/index.html",
    "href": "posts/006-tukey/index.html",
    "title": "Tukey’s test plot in adas.utils",
    "section": "",
    "text": "The new version v1.1.1 of the adas.utils package includes a new function to plot the results of Tukey’s test. The function is called ggTukey and it is used to plot the results of Tukey’s test provided by the stas::TukeyHSD function.\n\n\n\n\n\nJohn W. Tukey\n\n\nThe standard stats::TukeyHSD function returns an S3 object that has the print and plot methods. The result of the plot method, though, is honestly not really appealing. Let’s see how it works, by loading a dataset and running a Tukey’s test on it. We load an online dataset by using the adas.utils::examples_url function1, and we begin with a simple boxplot of the data.\n\nlibrary(tidyverse)\nlibrary(adas.utils)\n\ndata &lt;- examples_url(\"anova.dat\") %&gt;% \n  read.table(header=TRUE) %&gt;% \n  mutate(Cotton=factor(Cotton)) %&gt;% \n  glimpse()\n\nRows: 25\nColumns: 3\n$ Cotton      &lt;fct&gt; 15, 15, 15, 15, 15, 20, 20, 20, 20, 20, 25, 25, 25, 25, 25…\n$ Observation &lt;int&gt; 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5…\n$ Strength    &lt;int&gt; 7, 7, 15, 11, 9, 12, 17, 12, 18, 18, 14, 18, 18, 19, 19, 1…\n\ndata %&gt;% \n  ggplot(aes(x=Cotton, y=Strength, group=Cotton)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe Tukey’s test is built by using the aov function and the TukeyHSD function. The results are then plotted by the plot method of the TukeyHSD object:\n\ndata %&gt;% \n  aov(Strength ~ Cotton, data=.) %&gt;%\n  TukeyHSD() %&gt;% \n  plot()\n\n\n\n\n\n\n\n\nThe biggest problem with plot.TukeyHSD is that the labels of the differences are often partially hidden if there are many groups or the plot is too squat. This is the main reason for implementing an analogous function based on GGplot2 in adas.utils."
  },
  {
    "objectID": "posts/006-tukey/index.html#footnotes",
    "href": "posts/006-tukey/index.html#footnotes",
    "title": "Tukey’s test plot in adas.utils",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis function can load any data file listed on https://paolobosetti.quarto.pub/data↩︎"
  },
  {
    "objectID": "posts/004-adas.utils/index.html",
    "href": "posts/004-adas.utils/index.html",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "The package provides tools for dealing with factorial plan according to the Design of Experiments (DoE) protocols. The functions for dealing with DoE have names starting with fp_. As much as possible, we are aiming at a tidyverse-like syntax, so that the functions can be used in a pipe.\nWe are following conventions and techniques illustrated in the book Design and Analysis of Experiments by Douglas C. Montgomery.\n\n\n\n\n\n\n\nA hypercube, clearly impossible to represent in 2D\n\n\nYou can create a full factorial plan with the fp_design_matrix function, passing the number of factors:\n\n(dm &lt;- fp_design_matrix(2, rep=2) %&gt;% \n  mutate(Y=rnorm(n())))\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 8 × 7\n#&gt;   StdOrder RunOrder .treat  .rep     A     B       Y\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1        1        5 (1)        1    -1    -1 -0.439 \n#&gt; 2        2        8 a          1     1    -1  0.0520\n#&gt; 3        3        2 b          1    -1     1  0.101 \n#&gt; 4        4        6 ab         1     1     1  0.571 \n#&gt; 5        5        4 (1)        2    -1    -1 -1.23  \n#&gt; 6        6        3 a          2     1    -1 -2.40  \n#&gt; 7        7        7 b          2    -1     1  1.13  \n#&gt; 8        8        1 ab         2     1     1  0.0625\n\nIn this case, the factors are the first n capital letters.\nIf you want different factor names, use a right-side-only formula combining all the named factors with *:\n\nfp_design_matrix(~Speed*Weight)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ Speed * Weight \n#&gt;  Factors:  Speed Weight \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 4 × 7\n#&gt;   StdOrder RunOrder .treat       .rep Speed Weight Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        4 (1)             1    -1     -1 NA   \n#&gt; 2        2        1 speed           1     1     -1 NA   \n#&gt; 3        3        2 weight          1    -1      1 NA   \n#&gt; 4        4        3 speedweight     1     1      1 NA\n\nNOTE, though, that using custom factor names is discouraged, and won’t work as expected if you are using the functions for dealing with fractional factorial plans, especially for the analysis of alias structures among factors.\nThe yield column Y must then be completed according to the randomized RunOrder column.\nIt is possible to add custom scales to the factors, and also add names to the factors:\n\nfp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;%\n  fp_add_scale(A=c(20, 25), B=c(75, 125), suffix=\".scaled\")\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  Scaled factors:\n#&gt;     A: [20, 25]\n#&gt;     B: [75, 125]\n#&gt;  Factor names:\n#&gt;     A: Temperature\n#&gt;     B: Pressure\n#&gt;  \n#&gt; # A tibble: 4 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B A.scaled B.scaled Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        1 (1)        1    -1    -1       20       75 NA   \n#&gt; 2        2        4 a          1     1    -1       25       75 NA   \n#&gt; 3        3        2 b          1    -1     1       20      125 NA   \n#&gt; 4        4        3 ab         1     1     1       25      125 NA\n\n\n\n\nIf you want a \\(k^n\\) factorial plan with custom levels, pass the levels argument. In this case, though, the .treat column with Yates’ treatment codes would be NA:\n\nfp_design_matrix(2, levels=-1:1)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 0 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 9 × 6\n#&gt;   StdOrder RunOrder  .rep     A     B Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;\n#&gt; 1        1        8     1    -1    -1 NA   \n#&gt; 2        2        5     1     0    -1 NA   \n#&gt; 3        3        3     1     1    -1 NA   \n#&gt; 4        4        6     1    -1     0 NA   \n#&gt; 5        5        7     1     0     0 NA   \n#&gt; 6        6        1     1     1     0 NA   \n#&gt; 7        7        9     1    -1     1 NA   \n#&gt; 8        8        2     1     0     1 NA   \n#&gt; 9        9        4     1     1     1 NA\n\n\n\n\nYou can augment a plan by adding a central point, typically repeated:\n\nfp_design_matrix(3) %&gt;%\n  fp_augment_center(rep=4)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  centered \n#&gt;  \n#&gt; # A tibble: 12 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        5 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        8 a          1     1    -1    -1 NA   \n#&gt;  3        3        6 b          1    -1     1    -1 NA   \n#&gt;  4        4        4 ab         1     1     1    -1 NA   \n#&gt;  5        5        2 c          1    -1    -1     1 NA   \n#&gt;  6        6        1 ac         1     1    -1     1 NA   \n#&gt;  7        7        7 bc         1    -1     1     1 NA   \n#&gt;  8        8        3 abc        1     1     1     1 NA   \n#&gt;  9        9       11 center     1     0     0     0 NA   \n#&gt; 10       10       10 center     2     0     0     0 NA   \n#&gt; 11       11       12 center     3     0     0     0 NA   \n#&gt; 12       12        9 center     4     0     0     0 NA\n\nThen if needed (because the analysis show low p-value for the quadratic term) you can add axial points to get a central composite design:\n\nfp_design_matrix(3) %&gt;% \n  fp_augment_center(rep=3) %&gt;% \n  fp_augment_axial(rep=2)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  composite \n#&gt;  \n#&gt; # A tibble: 35 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        7 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        3 a          1     1    -1    -1 NA   \n#&gt;  3        3        2 b          1    -1     1    -1 NA   \n#&gt;  4        4        1 ab         1     1     1    -1 NA   \n#&gt;  5        5        5 c          1    -1    -1     1 NA   \n#&gt;  6        6        6 ac         1     1    -1     1 NA   \n#&gt;  7        7        8 bc         1    -1     1     1 NA   \n#&gt;  8        8        4 abc        1     1     1     1 NA   \n#&gt;  9        9        9 center     1     0     0     0 NA   \n#&gt; 10       10       11 center     2     0     0     0 NA   \n#&gt; # ℹ 25 more rows\n\n\n\nLet’s see a full example using the ccd_experiment_yield dataset, which contains a list of the yield data for three sequential experiments in a central composite design.\nFirst, we design a \\(3\\cdot 2^2\\) factorial plan, with two factors and two levels each:\n\nfp &lt;- fp_design_matrix(2, rep=3)\n\nIdeally, we would then sort the table according to the RunOrder column, and complete the Y column with the yield data from the the real experiments. For the sake of documenting the package, we can directly add the yield data from the base field of the ccd_experiment_yield dataset (which holds values in standard Yates’ order):\n\nfp$Y &lt;- ccd_experiment_yield$base\n\nNow we can fit a linear model to the data, and check the p-values of the ANOVA:\n\nfp %&gt;% \n  lm(Y ~ A*B, data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  105.06 7.058e-06 ***\n#&gt; B          1 131.224 131.224  279.46 1.659e-07 ***\n#&gt; A:B        1 216.931 216.931  461.99 2.311e-08 ***\n#&gt; Residuals  8   3.756   0.470                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAll factors and their interactions are significant. But is the two-level model enough? Let’s check for the quadratic terms, by augmenting the plan with a central point repeated 4 times. We also load the center field from the ccd_experiment_yield dataset:\n\nfpc &lt;- fp %&gt;% \n  fp_augment_center(rep=4)\n\nfpc$Y[fpc$.treat == \"center\"] &lt;- ccd_experiment_yield$center\n\nNow we can fit a model with the quadratic term, using either \\(A\\) or \\(B\\): since we only have a central point, we cannot discriminate which factor is contributing to the curvature in the response surface. We get:\n\nfpc %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  96.801 8.695e-07 ***\n#&gt; B          1 131.224 131.224 257.494 5.592e-09 ***\n#&gt; I(A^2)     1  15.204  15.204  29.834 0.0001972 ***\n#&gt; A:B        1 216.931 216.931 425.673 3.827e-10 ***\n#&gt; Residuals 11   5.606   0.510                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo the contribution of the quadratic term is significant. This means that we have to further augment the plan with axial points and investigate a Central Composite Design (CCD). Note: if the quadratic term contribution were not significant, we would have to remove the quadratic term from the model and accept the two-level model.\nSo let’s load the axial points from the axial field of the ccd_experiment_yield dataset, and fit a model with the quadratic terms and their interactions:\n\nfpccd &lt;- fpc %&gt;% \n  fp_augment_axial(rep=2)\n\nfpccd$Y[fpccd$.treat == \"axial\"] &lt;- ccd_experiment_yield$axial\n\nfpccd %&gt;% \n  lm(Y ~ A*B*I(A^2)*I(B^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;               Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    \n#&gt; A              1  75.196  75.196  94.1952 7.395e-08 ***\n#&gt; B              1 194.702 194.702 243.8964 1.097e-10 ***\n#&gt; I(A^2)         1 101.355 101.355 126.9638 1.017e-08 ***\n#&gt; I(B^2)         1   3.551   3.551   4.4479   0.05216 .  \n#&gt; A:B            1 216.931 216.931 271.7423 5.087e-11 ***\n#&gt; A:I(A^2)       1   0.235   0.235   0.2945   0.59530    \n#&gt; B:I(A^2)       1   1.046   1.046   1.3106   0.27022    \n#&gt; I(A^2):I(B^2)  1   0.490   0.490   0.6142   0.44542    \n#&gt; Residuals     15  11.974   0.798                       \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo we can finally state that a proper model would be Y ~ A*B+I(A^2):\n\nfpccd %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Y ~ A * B + I(A^2), data = .)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.64925 -0.60624  0.00919  0.65165  1.67506 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0156     0.3061   3.318  0.00362 ** \n#&gt; A             1.9390     0.2134   9.088 2.40e-08 ***\n#&gt; B             3.1201     0.2134  14.624 8.59e-12 ***\n#&gt; I(A^2)        2.9905     0.2834  10.552 2.20e-09 ***\n#&gt; A:B           4.2518     0.2754  15.437 3.32e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9541 on 19 degrees of freedom\n#&gt; Multiple R-squared:  0.9714, Adjusted R-squared:  0.9654 \n#&gt; F-statistic: 161.5 on 4 and 19 DF,  p-value: 2.191e-14\n\n\n\n\n\nOnce the design matrix is prepared, you typically want to save it to a file and use it for collecting data form experiments. You can use the write.csv function, but it is recommended to use the fp_write_csv function, which will also save the design matrix properties as comments:\n\ndm &lt;-  fp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;% \n  fp_add_scale(A=c(2, 12), B=c(40, 60), suffix=\"_s\") %&gt;%\n  fp_write_csv(\"design_matrix.csv\")\n\nNote that the fp_write_csv function invisibly returns the same design matrix, so you can use it in a pipe chain. Also, the CVS files has the rows arranged in the same order as the RunOrder column (i.e. randomized).\nOnce the CSV file has been completed, you can load it back into R using the fp_read_csv function:\n\ndm &lt;- dm %&gt;% \n  fp_read_csv(\"design_matrix.csv\")\n\nNote that fp_read_csv returns the design matrix reordered according to Yates’ standard order.\n\n\n\nIt is possible to divide a design matrix into a fractional factorial plan using the fp_fraction function. The fraction uses a defining relationship (dr) as \\(I=ABCD\\), which is mapped in R as a one side formula ~A*B*C*D.\nAny fraction is added to the factorial.plan object in the fraction attribute.\nA full \\(2^n\\) factorial plan can be reduced to a fractional factorial plan \\(2^{n-p}\\) by applying the fp_fraction function \\(p\\) times. For example, to get a \\(2^{5-2}\\) plan with the defining relationships \\(I=ABCD\\) and \\(I=BCDE\\):\n\nfp_design_matrix(5) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_fraction(~B*C*D*E)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C * D * E \n#&gt;  Factors:  A B C D E \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABCD I=BCDE \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 12\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C     D     E Y      ABCD  BCDE\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1        1        8 (1)        1    -1    -1    -1    -1    -1 NA        1     1\n#&gt; 2        7       14 bc         1    -1     1     1    -1    -1 NA        1     1\n#&gt; 3       11        6 bd         1    -1     1    -1     1    -1 NA        1     1\n#&gt; 4       13        4 cd         1    -1    -1     1     1    -1 NA        1     1\n#&gt; 5       20       24 abe        1     1     1    -1    -1     1 NA        1     1\n#&gt; 6       22       29 ace        1     1    -1     1    -1     1 NA        1     1\n#&gt; 7       26        2 ade        1     1    -1    -1     1     1 NA        1     1\n#&gt; 8       32       22 abcde      1     1     1     1     1     1 NA        1     1\n\nNote that with the remove option you can control if you want to keep both fractions, and later on filter(ABC==1) them out.\n\nfp_design_matrix(3) %&gt;% \n  fp_fraction(~A*B*C, remove=FALSE)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABC \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C Y       ABC\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;\n#&gt; 1        1        2 (1)        1    -1    -1    -1 NA       -1\n#&gt; 2        2        5 a          1     1    -1    -1 NA        1\n#&gt; 3        3        4 b          1    -1     1    -1 NA        1\n#&gt; 4        4        8 ab         1     1     1    -1 NA       -1\n#&gt; 5        5        1 c          1    -1    -1     1 NA        1\n#&gt; 6        6        7 ac         1     1    -1     1 NA       -1\n#&gt; 7        7        3 bc         1    -1     1     1 NA       -1\n#&gt; 8        8        6 abc        1     1     1     1 NA        1\n\nAlso, note that the remove option is sticky, so that when you can apply the fp_fraction function multiple times and the first time has the option set to remove=FALSE, then all the following fp_fraction calls will have the same option set to FALSE. Setting remove=FALSE to any of the following calls can have unexpected behavior.\n\n\n\nAny fraction of a factorial plan results in a set of aliases among effects. The package provides the following functions to deal with alias structures:\n\nfp_alias_matrix: returns a matrix with the alias structure of the factors in the design matrix. The alias matrix has a plot method.\nfp_all_drs: given a set of defining relationships, returns the dependent one.\nfp_merge_drs: given a set of defining relationships, returns the merged one, i.e. the one having all the factors.\nfp_gen2alias: given a generator (i.e. the right side of a DR) and an effect name as strings, calculates the resulting alias.\n\nFor example:\n\n(am &lt;- fp_alias_matrix(~A*B*C, ~B*C*D))\n#&gt; Defining relationships:\n#&gt;  I=ABC I=BCD I=AD \n#&gt; \n#&gt;      A B AB C AC BC ABC D AD BD ABD CD ACD BCD ABCD\n#&gt; A    0 0  0 0  0  1   0 3  0  0   0  0   0   0    2\n#&gt; B    0 0  0 0  1  0   0 0  0  0   3  2   0   0    0\n#&gt; AB   0 0  0 1  0  0   0 0  0  3   0  0   2   0    0\n#&gt; C    0 0  1 0  0  0   0 0  0  2   0  0   3   0    0\n#&gt; AC   0 1  0 0  0  0   0 0  0  0   2  3   0   0    0\n#&gt; BC   1 0  0 0  0  0   0 2  0  0   0  0   0   0    3\n#&gt; ABC  0 0  0 0  0  0   0 0  2  0   0  0   0   3    0\n#&gt; D    3 0  0 0  0  2   0 0  0  0   0  0   0   0    1\n#&gt; AD   0 0  0 0  0  0   2 0  0  0   0  0   0   1    0\n#&gt; BD   0 0  3 2  0  0   0 0  0  0   0  0   1   0    0\n#&gt; ABD  0 3  0 0  2  0   0 0  0  0   0  1   0   0    0\n#&gt; CD   0 2  0 0  3  0   0 0  0  0   1  0   0   0    0\n#&gt; ACD  0 0  2 3  0  0   0 0  0  1   0  0   0   0    0\n#&gt; BCD  0 0  0 0  0  0   3 0  1  0   0  0   0   0    0\n#&gt; ABCD 2 0  0 0  0  3   0 1  0  0   0  0   0   0    0\n\n\nam %&gt;% plot()\n\n\n\n\n\n\n\n\nThe design matrix can be converted to a tibble thanks to the proper as_tibble.design.matrix S3 method:\n\nam %&gt;% as_tibble()\n#&gt; # A tibble: 42 × 3\n#&gt;    Effect.x Effect.y generator\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    \n#&gt;  1 A        BC       ABC      \n#&gt;  2 A        D        AD       \n#&gt;  3 A        ABCD     BCD      \n#&gt;  4 B        AC       ABC      \n#&gt;  5 B        ABD      AD       \n#&gt;  6 B        CD       BCD      \n#&gt;  7 AB       C        ABC      \n#&gt;  8 AB       BD       AD       \n#&gt;  9 AB       ACD      BCD      \n#&gt; 10 C        AB       ABC      \n#&gt; # ℹ 32 more rows"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#full-factorial-plan",
    "href": "posts/004-adas.utils/index.html#full-factorial-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "A hypercube, clearly impossible to represent in 2D\n\n\nYou can create a full factorial plan with the fp_design_matrix function, passing the number of factors:\n\n(dm &lt;- fp_design_matrix(2, rep=2) %&gt;% \n  mutate(Y=rnorm(n())))\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 8 × 7\n#&gt;   StdOrder RunOrder .treat  .rep     A     B       Y\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1        1        5 (1)        1    -1    -1 -0.439 \n#&gt; 2        2        8 a          1     1    -1  0.0520\n#&gt; 3        3        2 b          1    -1     1  0.101 \n#&gt; 4        4        6 ab         1     1     1  0.571 \n#&gt; 5        5        4 (1)        2    -1    -1 -1.23  \n#&gt; 6        6        3 a          2     1    -1 -2.40  \n#&gt; 7        7        7 b          2    -1     1  1.13  \n#&gt; 8        8        1 ab         2     1     1  0.0625\n\nIn this case, the factors are the first n capital letters.\nIf you want different factor names, use a right-side-only formula combining all the named factors with *:\n\nfp_design_matrix(~Speed*Weight)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ Speed * Weight \n#&gt;  Factors:  Speed Weight \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 4 × 7\n#&gt;   StdOrder RunOrder .treat       .rep Speed Weight Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        4 (1)             1    -1     -1 NA   \n#&gt; 2        2        1 speed           1     1     -1 NA   \n#&gt; 3        3        2 weight          1    -1      1 NA   \n#&gt; 4        4        3 speedweight     1     1      1 NA\n\nNOTE, though, that using custom factor names is discouraged, and won’t work as expected if you are using the functions for dealing with fractional factorial plans, especially for the analysis of alias structures among factors.\nThe yield column Y must then be completed according to the randomized RunOrder column.\nIt is possible to add custom scales to the factors, and also add names to the factors:\n\nfp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;%\n  fp_add_scale(A=c(20, 25), B=c(75, 125), suffix=\".scaled\")\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  Scaled factors:\n#&gt;     A: [20, 25]\n#&gt;     B: [75, 125]\n#&gt;  Factor names:\n#&gt;     A: Temperature\n#&gt;     B: Pressure\n#&gt;  \n#&gt; # A tibble: 4 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B A.scaled B.scaled Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1        1        1 (1)        1    -1    -1       20       75 NA   \n#&gt; 2        2        4 a          1     1    -1       25       75 NA   \n#&gt; 3        3        2 b          1    -1     1       20      125 NA   \n#&gt; 4        4        3 ab         1     1     1       25      125 NA"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#custom-levels",
    "href": "posts/004-adas.utils/index.html#custom-levels",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "If you want a \\(k^n\\) factorial plan with custom levels, pass the levels argument. In this case, though, the .treat column with Yates’ treatment codes would be NA:\n\nfp_design_matrix(2, levels=-1:1)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B \n#&gt;  Factors:  A B \n#&gt;  Levels:  -1 0 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  plain \n#&gt;  \n#&gt; # A tibble: 9 × 6\n#&gt;   StdOrder RunOrder  .rep     A     B Y    \n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;\n#&gt; 1        1        8     1    -1    -1 NA   \n#&gt; 2        2        5     1     0    -1 NA   \n#&gt; 3        3        3     1     1    -1 NA   \n#&gt; 4        4        6     1    -1     0 NA   \n#&gt; 5        5        7     1     0     0 NA   \n#&gt; 6        6        1     1     1     0 NA   \n#&gt; 7        7        9     1    -1     1 NA   \n#&gt; 8        8        2     1     0     1 NA   \n#&gt; 9        9        4     1     1     1 NA"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#augment-a-plan",
    "href": "posts/004-adas.utils/index.html#augment-a-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "You can augment a plan by adding a central point, typically repeated:\n\nfp_design_matrix(3) %&gt;%\n  fp_augment_center(rep=4)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  centered \n#&gt;  \n#&gt; # A tibble: 12 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        5 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        8 a          1     1    -1    -1 NA   \n#&gt;  3        3        6 b          1    -1     1    -1 NA   \n#&gt;  4        4        4 ab         1     1     1    -1 NA   \n#&gt;  5        5        2 c          1    -1    -1     1 NA   \n#&gt;  6        6        1 ac         1     1    -1     1 NA   \n#&gt;  7        7        7 bc         1    -1     1     1 NA   \n#&gt;  8        8        3 abc        1     1     1     1 NA   \n#&gt;  9        9       11 center     1     0     0     0 NA   \n#&gt; 10       10       10 center     2     0     0     0 NA   \n#&gt; 11       11       12 center     3     0     0     0 NA   \n#&gt; 12       12        9 center     4     0     0     0 NA\n\nThen if needed (because the analysis show low p-value for the quadratic term) you can add axial points to get a central composite design:\n\nfp_design_matrix(3) %&gt;% \n  fp_augment_center(rep=3) %&gt;% \n  fp_augment_axial(rep=2)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  NA \n#&gt;  Type:  composite \n#&gt;  \n#&gt; # A tibble: 35 × 8\n#&gt;    StdOrder RunOrder .treat  .rep     A     B     C Y    \n#&gt;       &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt;  1        1        7 (1)        1    -1    -1    -1 NA   \n#&gt;  2        2        3 a          1     1    -1    -1 NA   \n#&gt;  3        3        2 b          1    -1     1    -1 NA   \n#&gt;  4        4        1 ab         1     1     1    -1 NA   \n#&gt;  5        5        5 c          1    -1    -1     1 NA   \n#&gt;  6        6        6 ac         1     1    -1     1 NA   \n#&gt;  7        7        8 bc         1    -1     1     1 NA   \n#&gt;  8        8        4 abc        1     1     1     1 NA   \n#&gt;  9        9        9 center     1     0     0     0 NA   \n#&gt; 10       10       11 center     2     0     0     0 NA   \n#&gt; # ℹ 25 more rows\n\n\n\nLet’s see a full example using the ccd_experiment_yield dataset, which contains a list of the yield data for three sequential experiments in a central composite design.\nFirst, we design a \\(3\\cdot 2^2\\) factorial plan, with two factors and two levels each:\n\nfp &lt;- fp_design_matrix(2, rep=3)\n\nIdeally, we would then sort the table according to the RunOrder column, and complete the Y column with the yield data from the the real experiments. For the sake of documenting the package, we can directly add the yield data from the base field of the ccd_experiment_yield dataset (which holds values in standard Yates’ order):\n\nfp$Y &lt;- ccd_experiment_yield$base\n\nNow we can fit a linear model to the data, and check the p-values of the ANOVA:\n\nfp %&gt;% \n  lm(Y ~ A*B, data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  105.06 7.058e-06 ***\n#&gt; B          1 131.224 131.224  279.46 1.659e-07 ***\n#&gt; A:B        1 216.931 216.931  461.99 2.311e-08 ***\n#&gt; Residuals  8   3.756   0.470                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAll factors and their interactions are significant. But is the two-level model enough? Let’s check for the quadratic terms, by augmenting the plan with a central point repeated 4 times. We also load the center field from the ccd_experiment_yield dataset:\n\nfpc &lt;- fp %&gt;% \n  fp_augment_center(rep=4)\n\nfpc$Y[fpc$.treat == \"center\"] &lt;- ccd_experiment_yield$center\n\nNow we can fit a model with the quadratic term, using either \\(A\\) or \\(B\\): since we only have a central point, we cannot discriminate which factor is contributing to the curvature in the response surface. We get:\n\nfpc %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1  49.331  49.331  96.801 8.695e-07 ***\n#&gt; B          1 131.224 131.224 257.494 5.592e-09 ***\n#&gt; I(A^2)     1  15.204  15.204  29.834 0.0001972 ***\n#&gt; A:B        1 216.931 216.931 425.673 3.827e-10 ***\n#&gt; Residuals 11   5.606   0.510                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo the contribution of the quadratic term is significant. This means that we have to further augment the plan with axial points and investigate a Central Composite Design (CCD). Note: if the quadratic term contribution were not significant, we would have to remove the quadratic term from the model and accept the two-level model.\nSo let’s load the axial points from the axial field of the ccd_experiment_yield dataset, and fit a model with the quadratic terms and their interactions:\n\nfpccd &lt;- fpc %&gt;% \n  fp_augment_axial(rep=2)\n\nfpccd$Y[fpccd$.treat == \"axial\"] &lt;- ccd_experiment_yield$axial\n\nfpccd %&gt;% \n  lm(Y ~ A*B*I(A^2)*I(B^2), data=.) %&gt;% \n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;               Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    \n#&gt; A              1  75.196  75.196  94.1952 7.395e-08 ***\n#&gt; B              1 194.702 194.702 243.8964 1.097e-10 ***\n#&gt; I(A^2)         1 101.355 101.355 126.9638 1.017e-08 ***\n#&gt; I(B^2)         1   3.551   3.551   4.4479   0.05216 .  \n#&gt; A:B            1 216.931 216.931 271.7423 5.087e-11 ***\n#&gt; A:I(A^2)       1   0.235   0.235   0.2945   0.59530    \n#&gt; B:I(A^2)       1   1.046   1.046   1.3106   0.27022    \n#&gt; I(A^2):I(B^2)  1   0.490   0.490   0.6142   0.44542    \n#&gt; Residuals     15  11.974   0.798                       \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSo we can finally state that a proper model would be Y ~ A*B+I(A^2):\n\nfpccd %&gt;% \n  lm(Y ~ A*B+I(A^2), data=.) %&gt;% \n  summary()\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Y ~ A * B + I(A^2), data = .)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1.64925 -0.60624  0.00919  0.65165  1.67506 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   1.0156     0.3061   3.318  0.00362 ** \n#&gt; A             1.9390     0.2134   9.088 2.40e-08 ***\n#&gt; B             3.1201     0.2134  14.624 8.59e-12 ***\n#&gt; I(A^2)        2.9905     0.2834  10.552 2.20e-09 ***\n#&gt; A:B           4.2518     0.2754  15.437 3.32e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9541 on 19 degrees of freedom\n#&gt; Multiple R-squared:  0.9714, Adjusted R-squared:  0.9654 \n#&gt; F-statistic: 161.5 on 4 and 19 DF,  p-value: 2.191e-14"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#save-toload-from-a-file",
    "href": "posts/004-adas.utils/index.html#save-toload-from-a-file",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "Once the design matrix is prepared, you typically want to save it to a file and use it for collecting data form experiments. You can use the write.csv function, but it is recommended to use the fp_write_csv function, which will also save the design matrix properties as comments:\n\ndm &lt;-  fp_design_matrix(2) %&gt;% \n  fp_add_names(A=\"Temperature\", B=\"Pressure\") %&gt;% \n  fp_add_scale(A=c(2, 12), B=c(40, 60), suffix=\"_s\") %&gt;%\n  fp_write_csv(\"design_matrix.csv\")\n\nNote that the fp_write_csv function invisibly returns the same design matrix, so you can use it in a pipe chain. Also, the CVS files has the rows arranged in the same order as the RunOrder column (i.e. randomized).\nOnce the CSV file has been completed, you can load it back into R using the fp_read_csv function:\n\ndm &lt;- dm %&gt;% \n  fp_read_csv(\"design_matrix.csv\")\n\nNote that fp_read_csv returns the design matrix reordered according to Yates’ standard order."
  },
  {
    "objectID": "posts/004-adas.utils/index.html#fractional-factorial-plan",
    "href": "posts/004-adas.utils/index.html#fractional-factorial-plan",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "It is possible to divide a design matrix into a fractional factorial plan using the fp_fraction function. The fraction uses a defining relationship (dr) as \\(I=ABCD\\), which is mapped in R as a one side formula ~A*B*C*D.\nAny fraction is added to the factorial.plan object in the fraction attribute.\nA full \\(2^n\\) factorial plan can be reduced to a fractional factorial plan \\(2^{n-p}\\) by applying the fp_fraction function \\(p\\) times. For example, to get a \\(2^{5-2}\\) plan with the defining relationships \\(I=ABCD\\) and \\(I=BCDE\\):\n\nfp_design_matrix(5) %&gt;% \n  fp_fraction(~A*B*C*D) %&gt;% \n  fp_fraction(~B*C*D*E)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C * D * E \n#&gt;  Factors:  A B C D E \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABCD I=BCDE \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 12\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C     D     E Y      ABCD  BCDE\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1        1        8 (1)        1    -1    -1    -1    -1    -1 NA        1     1\n#&gt; 2        7       14 bc         1    -1     1     1    -1    -1 NA        1     1\n#&gt; 3       11        6 bd         1    -1     1    -1     1    -1 NA        1     1\n#&gt; 4       13        4 cd         1    -1    -1     1     1    -1 NA        1     1\n#&gt; 5       20       24 abe        1     1     1    -1    -1     1 NA        1     1\n#&gt; 6       22       29 ace        1     1    -1     1    -1     1 NA        1     1\n#&gt; 7       26        2 ade        1     1    -1    -1     1     1 NA        1     1\n#&gt; 8       32       22 abcde      1     1     1     1     1     1 NA        1     1\n\nNote that with the remove option you can control if you want to keep both fractions, and later on filter(ABC==1) them out.\n\nfp_design_matrix(3) %&gt;% \n  fp_fraction(~A*B*C, remove=FALSE)\n#&gt;  Factorial Plan Design Matrix\n#&gt;  Defining Relationship:  ~ A * B * C \n#&gt;  Factors:  A B C \n#&gt;  Levels:  -1 1 \n#&gt;  Fraction:  I=ABC \n#&gt;  Type:  fractional \n#&gt;  \n#&gt; # A tibble: 8 × 9\n#&gt;   StdOrder RunOrder .treat  .rep     A     B     C Y       ABC\n#&gt;      &lt;int&gt;    &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt;\n#&gt; 1        1        2 (1)        1    -1    -1    -1 NA       -1\n#&gt; 2        2        5 a          1     1    -1    -1 NA        1\n#&gt; 3        3        4 b          1    -1     1    -1 NA        1\n#&gt; 4        4        8 ab         1     1     1    -1 NA       -1\n#&gt; 5        5        1 c          1    -1    -1     1 NA        1\n#&gt; 6        6        7 ac         1     1    -1     1 NA       -1\n#&gt; 7        7        3 bc         1    -1     1     1 NA       -1\n#&gt; 8        8        6 abc        1     1     1     1 NA        1\n\nAlso, note that the remove option is sticky, so that when you can apply the fp_fraction function multiple times and the first time has the option set to remove=FALSE, then all the following fp_fraction calls will have the same option set to FALSE. Setting remove=FALSE to any of the following calls can have unexpected behavior."
  },
  {
    "objectID": "posts/004-adas.utils/index.html#alias-structure",
    "href": "posts/004-adas.utils/index.html#alias-structure",
    "title": "Introducing the adas.utils package",
    "section": "",
    "text": "Any fraction of a factorial plan results in a set of aliases among effects. The package provides the following functions to deal with alias structures:\n\nfp_alias_matrix: returns a matrix with the alias structure of the factors in the design matrix. The alias matrix has a plot method.\nfp_all_drs: given a set of defining relationships, returns the dependent one.\nfp_merge_drs: given a set of defining relationships, returns the merged one, i.e. the one having all the factors.\nfp_gen2alias: given a generator (i.e. the right side of a DR) and an effect name as strings, calculates the resulting alias.\n\nFor example:\n\n(am &lt;- fp_alias_matrix(~A*B*C, ~B*C*D))\n#&gt; Defining relationships:\n#&gt;  I=ABC I=BCD I=AD \n#&gt; \n#&gt;      A B AB C AC BC ABC D AD BD ABD CD ACD BCD ABCD\n#&gt; A    0 0  0 0  0  1   0 3  0  0   0  0   0   0    2\n#&gt; B    0 0  0 0  1  0   0 0  0  0   3  2   0   0    0\n#&gt; AB   0 0  0 1  0  0   0 0  0  3   0  0   2   0    0\n#&gt; C    0 0  1 0  0  0   0 0  0  2   0  0   3   0    0\n#&gt; AC   0 1  0 0  0  0   0 0  0  0   2  3   0   0    0\n#&gt; BC   1 0  0 0  0  0   0 2  0  0   0  0   0   0    3\n#&gt; ABC  0 0  0 0  0  0   0 0  2  0   0  0   0   3    0\n#&gt; D    3 0  0 0  0  2   0 0  0  0   0  0   0   0    1\n#&gt; AD   0 0  0 0  0  0   2 0  0  0   0  0   0   1    0\n#&gt; BD   0 0  3 2  0  0   0 0  0  0   0  0   1   0    0\n#&gt; ABD  0 3  0 0  2  0   0 0  0  0   0  1   0   0    0\n#&gt; CD   0 2  0 0  3  0   0 0  0  0   1  0   0   0    0\n#&gt; ACD  0 0  2 3  0  0   0 0  0  1   0  0   0   0    0\n#&gt; BCD  0 0  0 0  0  0   3 0  1  0   0  0   0   0    0\n#&gt; ABCD 2 0  0 0  0  3   0 1  0  0   0  0   0   0    0\n\n\nam %&gt;% plot()\n\n\n\n\n\n\n\n\nThe design matrix can be converted to a tibble thanks to the proper as_tibble.design.matrix S3 method:\n\nam %&gt;% as_tibble()\n#&gt; # A tibble: 42 × 3\n#&gt;    Effect.x Effect.y generator\n#&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    \n#&gt;  1 A        BC       ABC      \n#&gt;  2 A        D        AD       \n#&gt;  3 A        ABCD     BCD      \n#&gt;  4 B        AC       ABC      \n#&gt;  5 B        ABD      AD       \n#&gt;  6 B        CD       BCD      \n#&gt;  7 AB       C        ABC      \n#&gt;  8 AB       BD       AD       \n#&gt;  9 AB       ACD      BCD      \n#&gt; 10 C        AB       ABC      \n#&gt; # ℹ 32 more rows"
  },
  {
    "objectID": "posts/004-adas.utils/index.html#plotting",
    "href": "posts/004-adas.utils/index.html#plotting",
    "title": "Introducing the adas.utils package",
    "section": "Plotting",
    "text": "Plotting\n\nNormal probability plot\nThe normal probability plot is provided as an alternative to the quantile-quantile plot:\n\ndf &lt;- tibble(\n  xn = rnorm(100, mean=20, sd=5),\n  xu = runif(100, min=0, max=40)\n)\n\ndf %&gt;% normplot(xn)\n\n\n\n\n\n\n\ndf %&gt;% normplot(xu)\n\n\n\n\n\n\n\n\n\n\nPareto chart\nThe Pareto chart is a bar chart that displays the relative importance of problems in a format that is very easy to interpret. The bars are sorted in descending order, and the cumulative percentage of the total is shown by the line.\nIt can prove useful in the context of factorial plans, to identify the most important factors, or in sensitivity analysis, to identify the most important parameters.\nThe package provides a generic function, pareto_chart, that can be used with a tibble (or a data frame), or with a linear model (an lm object). In the latter case, the function produces the Pareto chart of the model effects.\nFor the general case, when you have a tibble with values and names:\n\nset.seed(1)\ntibble(\n  val=rnorm(10, sd=5),\n  cat=LETTERS[1:length(val)]\n  ) %&gt;%\n  pareto_chart(labels=cat, values=val)\n\n\n\n\n\n\n\n\nFor the case of a linear model:\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  pareto_chart()\n\n\n\n\n\n\n\n\n\n\nDaniel’s plot\nIn case of non-replicated factorial plans, the Daniel’s plot can be used to identify the most important factors: a quantile-quantile plot of the factors effects shows the significant factors and interactions off the diagonal.\n\ndaniel_plot_qq(lm(Y~A*B*C*D, data=filtration))\n\n\n\n\n\n\n\n\nIf you prefer, you can rather use a half-normal plot:\n\nfiltration %&gt;% \n  lm(Y~A*B*C*D, data=.) %&gt;%\n  daniel_plot_hn(nlab=6, repel=TRUE)\n\n\n\n\n\n\n\n\nIt shows that none of the effects containing the B factor are significant, so we can reduce the model to Y~A*C*D:\n\nfiltration %&gt;% \n  lm(Y~A*C*D, data=.) %&gt;%\n  anova()\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: Y\n#&gt;           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \n#&gt; A          1 1870.56 1870.56 83.3677 1.667e-05 ***\n#&gt; C          1  390.06  390.06 17.3844 0.0031244 ** \n#&gt; D          1  855.56  855.56 38.1309 0.0002666 ***\n#&gt; A:C        1 1314.06 1314.06 58.5655 6.001e-05 ***\n#&gt; A:D        1 1105.56 1105.56 49.2730 0.0001105 ***\n#&gt; C:D        1    5.06    5.06  0.2256 0.6474830    \n#&gt; A:C:D      1   10.56   10.56  0.4708 0.5120321    \n#&gt; Residuals  8  179.50   22.44                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nEven better, the model can be further reduced to Y~A*C+A*D. Compare this conclusion with the last Pareto chart above."
  }
]