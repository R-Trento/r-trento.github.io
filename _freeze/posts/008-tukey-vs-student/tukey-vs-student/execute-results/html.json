{
  "hash": "86cbeb7a10f9515f266b88638cff7066",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tukey vs. Student\"\nauthor: \"Paolo Bosetti\"\ndate: \"04/10/2025\"\n# date-modified: today\nimage: \"image.png\"\nformat: html\ndraft: false\ncategories: \n  - R\n  - tidyverse\n  - inference\n  - Tukey\nabstract: >\n  To compare two samples, or groups, we can use a T-test. But if we want to compare more than two groups, we need to use Tukey's test. In this post we investigate the reason why a Tukey's test is more appropriate and robust than a set of pairwise T-tests for all possible combinations of groups. This is also an excuse to illustrate the power of `purrr` and `dplyr` packages, specifically for the use of `map`/`reduce`, `join_left`, and `pivot_longer`/`pivot_wider` functions.\n---\n\n::: {.cell}\n\n:::\n\n\n\n:::{.callout-note title=\"Packages that we need\"}\nIn this example, we are using the packages `tidyverse` and `adas.utils` version 1.1.4 (see <https://github.com/pbosetti/adas.utils>)\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(adas.utils)\n```\n:::\n\n\n:::\n\n# Repeated T-test vs. Tukey's test\n\n## The dataset\n\nLet us compare the result of a Tukey's test with a repeated Student's T-test on all combinations. We consider the `cotton` dataset, which is included in the `adas.utils` package from version 1.1.4. The dataset contains the tensile strength of mixed cotton-synthetic yarns with different cotton content:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncotton %>% \n  ggplot(aes(x=Cotton, y=Strength, group=Cotton)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](tukey-vs-student_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=16cm}\n:::\n:::\n\n\n\n## Inference on `Strength`\n\nNow we want to compare all the possibile combinations of treatmentswith a set of pairwise T-tests.\n\nFirst, we create the list of pairwise combinations, sorting each pair in descending order, as it is done by the `TukeyHSD` function:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlvl <- levels(cotton$Cotton) %>% \n  combn(2, FUN=sort, decreasing=T) %>% \n  as_tibble(.name_repair=\"minimal\") %>% \n  as.list() %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 10\n $ : chr [1:2] \"20\" \"15\"\n $ : chr [1:2] \"25\" \"15\"\n $ : chr [1:2] \"30\" \"15\"\n $ : chr [1:2] \"35\" \"15\"\n $ : chr [1:2] \"25\" \"20\"\n $ : chr [1:2] \"30\" \"20\"\n $ : chr [1:2] \"35\" \"20\"\n $ : chr [1:2] \"30\" \"25\"\n $ : chr [1:2] \"35\" \"25\"\n $ : chr [1:2] \"35\" \"30\"\n```\n\n\n:::\n:::\n\n\n\nNow, for each pair we do a T-test on the corresponding `cotton` data-frame subset, and accumulate into a new tibble the values of interest. We get the `df` table that is analogous to the `TukeyHSD` output:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf <- lvl %>% reduce(\\(acc, pair) {\n  tt <- cotton %>% \n    filter(Cotton %in% pair) %>% \n    t.test(Strength~Cotton, data=., var.equal=TRUE)\n  bind_rows(acc, list(\n    pair = paste0(pair[1], \"-\", pair[2]),\n    diff = -median(tt$conf.int),\n    lwr = -tt$conf.int[2],\n    upr = -tt$conf.int[1],\n    p.value = tt$p.value\n  ))\n}, .init=tibble()) \n\ndf %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|pair  |  diff|         lwr|        upr|   p.value|\n|:-----|-----:|-----------:|----------:|---------:|\n|20-15 |   5.6|   0.8740978| 10.3259022| 0.0257453|\n|25-15 |   7.8|   3.7398608| 11.8601392| 0.0021967|\n|30-15 |  11.8|   7.4246648| 16.1753352| 0.0002541|\n|35-15 |   1.0|  -3.5423014|  5.5423014| 0.6253800|\n|25-20 |   2.2|  -1.6724395|  6.0724395| 0.2265324|\n|30-20 |   6.2|   1.9982605| 10.4017395| 0.0093233|\n|35-20 |  -4.6|  -8.9753352| -0.2246648| 0.0415629|\n|30-25 |   4.0|   0.5641312|  7.4358688| 0.0277266|\n|35-25 |  -6.8| -10.4461127| -3.1538873| 0.0026133|\n|35-30 | -10.8| -14.7941163| -6.8058837| 0.0002496|\n\n\n:::\n:::\n\n\n\nTo be compared with Tukey's values:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nttdf <- TukeyHSD(aov(lm(Strength~Cotton, data=cotton)))$Cotton %>% \n  as.data.frame() %>% \n  rownames_to_column(var=\"pair\") %>% \n  rename(p.value=`p adj`)\nttdf %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|pair  |  diff|         lwr|        upr|   p.value|\n|:-----|-----:|-----------:|----------:|---------:|\n|20-15 |   5.6|   0.2270417| 10.9729583| 0.0385024|\n|25-15 |   7.8|   2.4270417| 13.1729583| 0.0025948|\n|30-15 |  11.8|   6.4270417| 17.1729583| 0.0000190|\n|35-15 |   1.0|  -4.3729583|  6.3729583| 0.9797709|\n|25-20 |   2.2|  -3.1729583|  7.5729583| 0.7372438|\n|30-20 |   6.2|   0.8270417| 11.5729583| 0.0188936|\n|35-20 |  -4.6|  -9.9729583|  0.7729583| 0.1162970|\n|30-25 |   4.0|  -1.3729583|  9.3729583| 0.2101089|\n|35-25 |  -6.8| -12.1729583| -1.4270417| 0.0090646|\n|35-30 | -10.8| -16.1729583| -5.4270417| 0.0000624|\n\n\n:::\n:::\n\n\n\nNow let's join both tables and make a common plot:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompared <- df %>% \n  left_join(ttdf, by=join_by(pair), suffix=c(\".student\", \".tukey\")) %>% \n  pivot_longer(-pair, names_to = c(\"stat\", \"test\"), names_pattern = \"(.*)\\\\.(student|tukey)$\") %>% \n  pivot_wider(names_from = stat)\n\ncompared %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|pair  |test    |  diff|         lwr|        upr|   p.value|\n|:-----|:-------|-----:|-----------:|----------:|---------:|\n|20-15 |student |   5.6|   0.8740978| 10.3259022| 0.0257453|\n|20-15 |tukey   |   5.6|   0.2270417| 10.9729583| 0.0385024|\n|25-15 |student |   7.8|   3.7398608| 11.8601392| 0.0021967|\n|25-15 |tukey   |   7.8|   2.4270417| 13.1729583| 0.0025948|\n|30-15 |student |  11.8|   7.4246648| 16.1753352| 0.0002541|\n|30-15 |tukey   |  11.8|   6.4270417| 17.1729583| 0.0000190|\n|35-15 |student |   1.0|  -3.5423014|  5.5423014| 0.6253800|\n|35-15 |tukey   |   1.0|  -4.3729583|  6.3729583| 0.9797709|\n|25-20 |student |   2.2|  -1.6724395|  6.0724395| 0.2265324|\n|25-20 |tukey   |   2.2|  -3.1729583|  7.5729583| 0.7372438|\n|30-20 |student |   6.2|   1.9982605| 10.4017395| 0.0093233|\n|30-20 |tukey   |   6.2|   0.8270417| 11.5729583| 0.0188936|\n|35-20 |student |  -4.6|  -8.9753352| -0.2246648| 0.0415629|\n|35-20 |tukey   |  -4.6|  -9.9729583|  0.7729583| 0.1162970|\n|30-25 |student |   4.0|   0.5641312|  7.4358688| 0.0277266|\n|30-25 |tukey   |   4.0|  -1.3729583|  9.3729583| 0.2101089|\n|35-25 |student |  -6.8| -10.4461127| -3.1538873| 0.0026133|\n|35-25 |tukey   |  -6.8| -12.1729583| -1.4270417| 0.0090646|\n|35-30 |student | -10.8| -14.7941163| -6.8058837| 0.0002496|\n|35-30 |tukey   | -10.8| -16.1729583| -5.4270417| 0.0000624|\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompared %>%\n  ggplot(aes(x=diff, y=pair, color=test)) + \n  geom_point() + \n  geom_errorbar(aes(xmin=lwr, xmax=upr), width=0.5, position=position_dodge()) + \n  geom_vline(xintercept=0, color=\"red\") +\n  labs(x=\"Difference\", y=\"Pair\", title=\"95% pairwise confidence level\")\n```\n\n::: {.cell-output-display}\n![](tukey-vs-student_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=16cm}\n:::\n:::\n\n\n\n## The Family-Wise Error Rate\n\n:::{.callout-important title=\"The Family-Wise Error Rate\"}\nAs expected, the Tukey's test in the last plot shows larger confidence intervals, that is, it has reduced chances of a false positive (Type I Error). More specifically, Tukey's test controls the **family-wise error rate (FWER)** --- the probability of making any false positive in the full set of comparisons.\n:::\n\nLet's see why. If we set a confidence level of 0.95, it means that the probability of not making a Type I error on **a single** T-test is 0.95.\n\nFor 3 independent tests, the probability of no Type I error at all (in any of the tests) is:\n$$\n0.95^3 \\approx 0.857\n$$\nSo the chance of making at least one Type I error is:\n$$\n1 - 0.95^3 \\approx 0.143 \\quad \\text{(14.3\\%)}\n$$\nThat's almost triple the risk you thought you were accepting! Furthermore, this risk increases exponentially with the number of comparisons. Given $n$ elements, the number of possible combinations of $k$ elements is given by the **binomial coefficient**:\n$$\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n$$\nIn R, the latter is provided by the `choose(n, k)` function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchoose(5, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n:::\n\n\n\nso, with increasing number of classes to be compared, this is what happens to the probability of committing **at least one** Type-I error:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n2:15 %>% reduce(\\(acc, k) {\n    nt <- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-0.95^nt)\n    )\n  }, .init=tibble()) %>% \n  ggplot(aes(x=n, y=p)) +\n  geom_point() +\n  geom_line() +\n  ylim(0, 1) +\n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\")\n```\n\n::: {.cell-output-display}\n![](tukey-vs-student_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=16cm}\n:::\n:::\n\n\n\nAnd what happens if we change the confidence level? Let's see, by creating a parametric plot similar to the ast one, but with different confidence levels. First we factor the last `reduce` opration into a function, `FWER`, that takes the confidence level as an argument. The function returns a tibble with the number of classes and the corresponding probability of Type I error.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nFWER <- function(levels, conf.int=0.95) {\n  reduce(levels, \\(acc, k) {\n    nt <- choose(k, 2)\n    bind_rows(acc,\n      list(n=k, p=1-conf.int^nt)\n    )\n  }, .init=tibble()) \n}\n```\n:::\n\n\n\nThen we apply the `FWER` function to a set of confidence levels, and join the results into a single tibble via the usual `reduce`, and finally, we plot the results:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncl <- c(0.9, 0.95, 0.99, 0.995, 0.999) \nN <- 2:15\ncl %>% \n  reduce(\\(acc, ci) {\n    fwer <- FWER(N, ci) %>% rename(!!paste0(\"cl-\", ci):=p)\n    left_join(acc, fwer, by=join_by(n))\n  }, .init=tibble(n=N)) %>% \n  pivot_longer(-n, names_to = c(NA, \"cl\"), names_pattern=\"(cl-)(.*)\") %>% \n  ggplot(aes(x=n, y=value, color=cl)) + \n  geom_point() + \n  geom_line() + \n  ylim(0, 1) + \n  labs(\n    x=\"number of classes\", \n    y=\"probability of Type-I Error\", \n    color=\"Conf. level\")\n```\n\n::: {.cell-output-display}\n![](tukey-vs-student_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=16cm}\n:::\n:::\n\n\n\n\n\n\n\n:::thatsall\nThat's all, folks!\n:::",
    "supporting": [
      "tukey-vs-student_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}